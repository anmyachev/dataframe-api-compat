{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Dataframe API Compat","text":"<p>Extremely lightweight compatibility layer between pandas and Polars:</p> <ul> <li>\u2705 No dependencies.</li> <li>\u2705 Lightweight: wheel is smaller than 30 kB.</li> <li>\u2705 Simple, minimal, and predictable.</li> </ul> <p>No need to choose - support both with ease!</p>"},{"location":"#whos-this-for","title":"Who's this for?","text":"<p>Anyone wishing to write a library/application/service which consumes dataframes, and wishing to make it completely dataframe-agnostic.</p>"},{"location":"#lets-get-started","title":"Let's get started!","text":"<ul> <li>Installation</li> <li>Quick start</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>First, make sure you have created and activated a Python3.8+ virtual environment.</p> <p>Then, run <pre><code>python -m pip install dataframe-api-compat\n</code></pre></p> <p>Then, if you start the Python REPL and see the following: <pre><code>&gt;&gt;&gt; import dataframe_api_compat\n&gt;&gt;&gt; dataframe_api_compat.__version__\n'0.2.6'\n</code></pre> then installation worked correctly!</p>"},{"location":"pandas-column/","title":"Pandas Column","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.column","title":"<code>column: pd.Series[Any]</code>  <code>property</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.dtype","title":"<code>dtype: DType</code>  <code>property</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.name","title":"<code>name: str</code>  <code>property</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.parent_dataframe","title":"<code>parent_dataframe: DataFrame | None</code>  <code>property</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__add__","title":"<code>__add__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__and__","title":"<code>__and__(other: Column | bool | Scalar) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__column_namespace__","title":"<code>__column_namespace__() -&gt; dataframe_api_compat.pandas_standard.Namespace</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__divmod__","title":"<code>__divmod__(other: Column | Any) -&gt; tuple[Column, Column]</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__eq__","title":"<code>__eq__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__floordiv__","title":"<code>__floordiv__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__ge__","title":"<code>__ge__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__gt__","title":"<code>__gt__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__init__","title":"<code>__init__(series: pd.Series[Any], *, df: DataFrame | None, api_version: str, is_persisted: bool = False) -&gt; None</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__init__--parameters","title":"Parameters","text":"<p>df     DataFrame this column originates from.</p>"},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__invert__","title":"<code>__invert__() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__iter__","title":"<code>__iter__() -&gt; NoReturn</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__le__","title":"<code>__le__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__lt__","title":"<code>__lt__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__mod__","title":"<code>__mod__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__mul__","title":"<code>__mul__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__ne__","title":"<code>__ne__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__or__","title":"<code>__or__(other: Column | bool | Scalar) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__pow__","title":"<code>__pow__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__radd__","title":"<code>__radd__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__rand__","title":"<code>__rand__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__repr__","title":"<code>__repr__() -&gt; str</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__rfloordiv__","title":"<code>__rfloordiv__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__rmod__","title":"<code>__rmod__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__rmul__","title":"<code>__rmul__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__ror__","title":"<code>__ror__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__rpow__","title":"<code>__rpow__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__rsub__","title":"<code>__rsub__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__rtruediv__","title":"<code>__rtruediv__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__sub__","title":"<code>__sub__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.__truediv__","title":"<code>__truediv__(other: Column | Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.all","title":"<code>all(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.any","title":"<code>any(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.cumulative_max","title":"<code>cumulative_max(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.cumulative_min","title":"<code>cumulative_min(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.cumulative_prod","title":"<code>cumulative_prod(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.cumulative_sum","title":"<code>cumulative_sum(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.day","title":"<code>day() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.fill_nan","title":"<code>fill_nan(value: float | NullType | Scalar) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.fill_null","title":"<code>fill_null(value: Any) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.filter","title":"<code>filter(mask: Column) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.floor","title":"<code>floor(frequency: str) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.take","title":"<code>take(indices: Column) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.get_value","title":"<code>get_value(row_number: int) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.hour","title":"<code>hour() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.is_in","title":"<code>is_in(values: Column) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.is_nan","title":"<code>is_nan() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.is_null","title":"<code>is_null() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.iso_weekday","title":"<code>iso_weekday() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.max","title":"<code>max(*, skip_nulls: bool | Scalar = True) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.mean","title":"<code>mean(*, skip_nulls: bool | Scalar = True) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.median","title":"<code>median(*, skip_nulls: bool | Scalar = True) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.microsecond","title":"<code>microsecond() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.min","title":"<code>min(*, skip_nulls: bool | Scalar = True) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.minute","title":"<code>minute() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.month","title":"<code>month() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.nanosecond","title":"<code>nanosecond() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.persist","title":"<code>persist() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.prod","title":"<code>prod(*, skip_nulls: bool | Scalar = True) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.rename","title":"<code>rename(name: str | Scalar) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.second","title":"<code>second() -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.shift","title":"<code>shift(offset: int | Scalar) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.slice_rows","title":"<code>slice_rows(start: int | None, stop: int | None, step: int | None) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.sort","title":"<code>sort(*, ascending: bool = True, nulls_position: Literal['first', 'last'] = 'last') -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.sorted_indices","title":"<code>sorted_indices(*, ascending: bool = True, nulls_position: Literal['first', 'last'] = 'last') -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.std","title":"<code>std(*, correction: float | Scalar | NullType = 1.0, skip_nulls: bool | Scalar = True) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.sum","title":"<code>sum(*, skip_nulls: bool | Scalar = True) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.to_array","title":"<code>to_array() -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.unique_indices","title":"<code>unique_indices(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.unix_timestamp","title":"<code>unix_timestamp(*, time_unit: str | Scalar = 's') -&gt; Column</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.var","title":"<code>var(*, correction: float | Scalar | NullType = 1.0, skip_nulls: bool | Scalar = True) -&gt; Any</code>","text":""},{"location":"pandas-column/#dataframe_api_compat.pandas_standard.Column.year","title":"<code>year() -&gt; Column</code>","text":""},{"location":"pandas-dataframe/","title":"Pandas DataFrame","text":"<p>             Bases: <code>DataFrame</code></p> <p>dataframe object</p> Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>class DataFrame(DataFrameT):\n    \"\"\"dataframe object\"\"\"\n\n    def __init__(\n        self,\n        dataframe: pd.DataFrame,\n        *,\n        api_version: str,\n        is_persisted: bool = False,\n    ) -&gt; None:\n        self._is_persisted = is_persisted\n        self._validate_columns(dataframe.columns)\n        self._dataframe = dataframe.reset_index(drop=True)\n        self._api_version = api_version\n\n    # Validation helper methods\n\n    def _validate_is_persisted(self) -&gt; pd.DataFrame:\n        if not self._is_persisted:\n            msg = \"Method requires you to call `.persist` first.\\n\\nNote: `.persist` forces materialisation in lazy libraries and so should be called as late as possible in your pipeline. Use with care.\"\n            raise ValueError(\n                msg,\n            )\n        return self.dataframe\n\n    def __repr__(self) -&gt; str:  # pragma: no cover\n        header = f\" Standard DataFrame (api_version={self._api_version}) \"\n        length = len(header)\n        return (\n            \"\u250c\"\n            + \"\u2500\" * length\n            + \"\u2510\\n\"\n            + f\"|{header}|\\n\"\n            + \"| Add `.dataframe` to see native output         |\\n\"\n            + \"\u2514\"\n            + \"\u2500\" * length\n            + \"\u2518\\n\"\n        )\n\n    def _validate_columns(self, columns: Sequence[str]) -&gt; None:\n        counter = collections.Counter(columns)\n        for col, count in counter.items():\n            if count &gt; 1:\n                msg = f\"Expected unique column names, got {col} {count} time(s)\"\n                raise ValueError(\n                    msg,\n                )\n\n    def _validate_booleanness(self) -&gt; None:\n        if not (\n            (self.dataframe.dtypes == \"bool\") | (self.dataframe.dtypes == \"boolean\")\n        ).all():\n            msg = \"'any' can only be called on DataFrame where all dtypes are 'bool'\"\n            raise TypeError(\n                msg,\n            )\n\n    def _from_dataframe(self, df: pd.DataFrame) -&gt; DataFrame:\n        return DataFrame(\n            df,\n            api_version=self._api_version,\n            is_persisted=self._is_persisted,\n        )\n\n    # Properties\n    @property\n    def schema(self) -&gt; dict[str, DType]:\n        return {\n            column_name: dataframe_api_compat.pandas_standard.map_pandas_dtype_to_standard_dtype(\n                dtype.name,\n            )\n            for column_name, dtype in self.dataframe.dtypes.items()\n        }\n\n    @property\n    def dataframe(self) -&gt; pd.DataFrame:\n        return self._dataframe\n\n    @property\n    def column_names(self) -&gt; list[str]:\n        return self.dataframe.columns.tolist()  # type: ignore[no-any-return]\n\n    # In the Standard\n\n    def __dataframe_namespace__(\n        self,\n    ) -&gt; dataframe_api_compat.pandas_standard.Namespace:\n        return dataframe_api_compat.pandas_standard.Namespace(\n            api_version=self._api_version,\n        )\n\n    def iter_columns(self) -&gt; Iterator[Column]:\n        return (self.col(col_name) for col_name in self.column_names)\n\n    def col(self, name: str) -&gt; Column:\n        from dataframe_api_compat.pandas_standard.column_object import Column\n\n        return Column(\n            self.dataframe.loc[:, name],\n            df=None if self._is_persisted else self,\n            api_version=self._api_version,\n            is_persisted=self._is_persisted,\n        )\n\n    def shape(self) -&gt; tuple[int, int]:\n        df = self._validate_is_persisted()\n        return df.shape  # type: ignore[no-any-return]\n\n    def group_by(self, *keys: str) -&gt; GroupBy:\n        from dataframe_api_compat.pandas_standard.group_by_object import GroupBy\n\n        for key in keys:\n            if key not in self.column_names:\n                msg = f\"key {key} not present in DataFrame's columns\"\n                raise KeyError(msg)\n        return GroupBy(self, keys, api_version=self._api_version)\n\n    def select(self, *columns: str) -&gt; DataFrame:\n        cols = list(columns)\n        if cols and isinstance(cols[0], (list, tuple)):\n            msg = f\"Expected iterable of column names, but the first element is: {type(cols[0])}\"\n            raise TypeError(msg)\n        return self._from_dataframe(\n            self.dataframe.loc[:, list(columns)],\n        )\n\n    def take(\n        self,\n        indices: Column,\n    ) -&gt; DataFrame:\n        _indices = validate_comparand(self, indices)\n        return self._from_dataframe(\n            self.dataframe.iloc[_indices.to_list(), :],\n        )\n\n    def slice_rows(\n        self,\n        start: int | None,\n        stop: int | None,\n        step: int | None,\n    ) -&gt; DataFrame:\n        return self._from_dataframe(self.dataframe.iloc[start:stop:step])\n\n    def filter(\n        self,\n        mask: Column,\n    ) -&gt; DataFrame:\n        _mask = validate_comparand(self, mask)\n        df = self.dataframe\n        df = df.loc[_mask]\n        return self._from_dataframe(df)\n\n    def assign(\n        self,\n        *columns: Column,\n    ) -&gt; DataFrame:\n        from dataframe_api_compat.pandas_standard.column_object import Column\n\n        df = self.dataframe.copy()  # TODO: remove defensive copy with CoW?\n        for column in columns:\n            if not isinstance(column, Column):\n                msg = f\"Expected iterable of Column, but the first element is: {type(column)}\"\n                raise TypeError(msg)\n            _series = validate_comparand(self, column)\n            df[_series.name] = _series\n        return self._from_dataframe(df)\n\n    def drop(self, *labels: str) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.drop(list(labels), axis=1),\n        )\n\n    def rename(self, mapping: Mapping[str, str]) -&gt; DataFrame:\n        if not isinstance(mapping, collections.abc.Mapping):\n            msg = f\"Expected Mapping, got: {type(mapping)}\"\n            raise TypeError(msg)\n        return self._from_dataframe(\n            self.dataframe.rename(columns=mapping),\n        )\n\n    def get_column_names(self) -&gt; list[str]:\n        # DO NOT REMOVE\n        # This one is used in upstream tests - even if deprecated,\n        # just leave it in for backwards compatibility\n        return self.dataframe.columns.tolist()  # type: ignore[no-any-return]\n\n    def sort(\n        self,\n        *keys: str,\n        ascending: Sequence[bool] | bool = True,\n        nulls_position: Literal[\"first\", \"last\"] = \"last\",\n    ) -&gt; DataFrame:\n        if not keys:\n            keys = self.dataframe.columns.tolist()\n        df = self.dataframe\n        return self._from_dataframe(\n            df.sort_values(list(keys), ascending=ascending),\n        )\n\n    # Binary operations\n\n    def __eq__(self, other: AnyScalar) -&gt; DataFrame:  # type: ignore[override]\n        return self._from_dataframe(self.dataframe.__eq__(other))\n\n    def __ne__(self, other: AnyScalar) -&gt; DataFrame:  # type: ignore[override]\n        return self._from_dataframe(self.dataframe.__ne__(other))\n\n    def __ge__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(self.dataframe.__ge__(other))\n\n    def __gt__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(self.dataframe.__gt__(other))\n\n    def __le__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(self.dataframe.__le__(other))\n\n    def __lt__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(self.dataframe.__lt__(other))\n\n    def __and__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.__and__(other),\n        )\n\n    def __rand__(self, other: Column | AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self.__and__(_other)\n\n    def __or__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(self.dataframe.__or__(_other))\n\n    def __ror__(self, other: Column | AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self.__or__(_other)\n\n    def __add__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.__add__(_other),\n        )\n\n    def __radd__(self, other: Column | AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self.__add__(_other)\n\n    def __sub__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.__sub__(_other),\n        )\n\n    def __rsub__(self, other: Column | AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return -1 * self.__sub__(_other)\n\n    def __mul__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.__mul__(_other),\n        )\n\n    def __rmul__(self, other: Column | AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self.__mul__(_other)\n\n    def __truediv__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.__truediv__(_other),\n        )\n\n    def __rtruediv__(self, other: Column | AnyScalar) -&gt; DataFrame:  # pragma: no cover\n        _other = validate_comparand(self, other)\n        raise NotImplementedError\n\n    def __floordiv__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.__floordiv__(_other),\n        )\n\n    def __rfloordiv__(self, other: Column | AnyScalar) -&gt; DataFrame:  # pragma: no cover\n        _other = validate_comparand(self, other)\n        raise NotImplementedError\n\n    def __pow__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.__pow__(_other),\n        )\n\n    def __rpow__(self, other: Column | AnyScalar) -&gt; DataFrame:  # pragma: no cover\n        _other = validate_comparand(self, other)\n        raise NotImplementedError\n\n    def __mod__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.__mod__(other),\n        )\n\n    def __rmod__(self, other: Column | AnyScalar) -&gt; DataFrame:  # type: ignore[misc]  # pragma: no cover\n        _other = validate_comparand(self, other)\n        raise NotImplementedError\n\n    def __divmod__(\n        self,\n        other: DataFrame | AnyScalar,\n    ) -&gt; tuple[DataFrame, DataFrame]:\n        _other = validate_comparand(self, other)\n        quotient, remainder = self.dataframe.__divmod__(_other)\n        return self._from_dataframe(quotient), self._from_dataframe(\n            remainder,\n        )\n\n    # Unary\n\n    def __invert__(self) -&gt; DataFrame:\n        self._validate_booleanness()\n        return self._from_dataframe(self.dataframe.__invert__())\n\n    def __iter__(self) -&gt; NoReturn:\n        raise NotImplementedError\n\n    # Reductions\n\n    def any(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        self._validate_booleanness()\n        return self._from_dataframe(\n            self.dataframe.any().to_frame().T,\n        )\n\n    def all(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        self._validate_booleanness()\n        return self._from_dataframe(\n            self.dataframe.all().to_frame().T,\n        )\n\n    def min(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.min().to_frame().T,\n        )\n\n    def max(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.max().to_frame().T,\n        )\n\n    def sum(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.sum().to_frame().T,\n        )\n\n    def prod(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.prod().to_frame().T,\n        )\n\n    def median(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.median().to_frame().T,\n        )\n\n    def mean(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.mean().to_frame().T,\n        )\n\n    def std(\n        self,\n        *,\n        correction: float | Scalar | NullType = 1.0,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.std().to_frame().T,\n        )\n\n    def var(\n        self,\n        *,\n        correction: float | Scalar | NullType = 1.0,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.var().to_frame().T,\n        )\n\n    # Transformations\n\n    def is_null(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        result: list[pd.Series] = []\n        for column in self.dataframe.columns:\n            result.append(self.dataframe[column].isna())\n        return self._from_dataframe(pd.concat(result, axis=1))\n\n    def is_nan(self) -&gt; DataFrame:\n        return self.assign(*[col.is_nan() for col in self.iter_columns()])\n\n    def fill_nan(self, value: float | Scalar | NullType) -&gt; DataFrame:\n        _value = validate_comparand(self, value)\n        new_cols = {}\n        df = self.dataframe\n        for col in df.columns:\n            ser = df[col].copy()\n            if is_extension_array_dtype(ser.dtype):\n                if self.__dataframe_namespace__().is_null(_value):\n                    ser[np.isnan(ser).fillna(False).to_numpy(bool)] = pd.NA\n                else:\n                    ser[np.isnan(ser).fillna(False).to_numpy(bool)] = _value\n            else:\n                if self.__dataframe_namespace__().is_null(_value):\n                    ser[np.isnan(ser).fillna(False).to_numpy(bool)] = np.nan\n                else:\n                    ser[np.isnan(ser).fillna(False).to_numpy(bool)] = _value\n            new_cols[col] = ser\n        df = pd.DataFrame(new_cols)\n        return self._from_dataframe(df)\n\n    def fill_null(\n        self,\n        value: AnyScalar,\n        *,\n        column_names: list[str] | None = None,\n    ) -&gt; DataFrame:\n        if column_names is None:\n            column_names = self.dataframe.columns.tolist()\n        assert isinstance(column_names, list)  # help type checkers\n        return self.assign(\n            *[\n                col.fill_null(value)\n                for col in self.iter_columns()\n                if col.name in column_names\n            ],\n        )\n\n    def drop_nulls(\n        self,\n        *,\n        column_names: list[str] | None = None,\n    ) -&gt; DataFrame:\n        namespace = self.__dataframe_namespace__()\n        mask = ~namespace.any_horizontal(\n            *[\n                self.col(col_name).is_null()\n                for col_name in column_names or self.column_names\n            ],\n        )\n        return self.filter(mask)\n\n    # Other\n\n    def join(\n        self,\n        other: DataFrame,\n        *,\n        how: Literal[\"left\", \"inner\", \"outer\"],\n        left_on: str | list[str],\n        right_on: str | list[str],\n    ) -&gt; DataFrame:\n        if how not in [\"left\", \"inner\", \"outer\"]:\n            msg = f\"Expected 'left', 'inner', 'outer', got: {how}\"\n            raise ValueError(msg)\n\n        if isinstance(left_on, str):\n            left_on = [left_on]\n        if isinstance(right_on, str):\n            right_on = [right_on]\n\n        if overlap := (set(self.column_names) - set(left_on)).intersection(\n            set(other.column_names) - set(right_on),\n        ):\n            msg = f\"Found overlapping columns in join: {overlap}. Please rename columns to avoid this.\"\n            raise ValueError(msg)\n\n        return self._from_dataframe(\n            self.dataframe.merge(\n                other.dataframe,\n                left_on=left_on,\n                right_on=right_on,\n                how=how,\n            ),\n        )\n\n    def persist(self) -&gt; DataFrame:\n        if self._is_persisted:\n            warnings.warn(\n                \"Calling `.persist` on DataFrame that was already persisted\",\n                UserWarning,\n                stacklevel=2,\n            )\n        return DataFrame(\n            self.dataframe,\n            api_version=self._api_version,\n            is_persisted=True,\n        )\n\n    # Conversion\n\n    def to_array(self, dtype: DType | None = None) -&gt; Any:\n        self._validate_is_persisted()\n        return self.dataframe.to_numpy()\n\n    def cast(self, dtypes: Mapping[str, DType]) -&gt; DataFrame:\n        from dataframe_api_compat.pandas_standard import (\n            map_standard_dtype_to_pandas_dtype,\n        )\n\n        df = self._dataframe\n        return self._from_dataframe(\n            df.astype(\n                {\n                    col: map_standard_dtype_to_pandas_dtype(dtype)\n                    for col, dtype in dtypes.items()\n                },\n            ),\n        )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.column_names","title":"<code>column_names: list[str]</code>  <code>property</code>","text":""},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.dataframe","title":"<code>dataframe: pd.DataFrame</code>  <code>property</code>","text":""},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.schema","title":"<code>schema: dict[str, DType]</code>  <code>property</code>","text":""},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__add__","title":"<code>__add__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __add__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.__add__(_other),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__and__","title":"<code>__and__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __and__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.__and__(other),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__dataframe_namespace__","title":"<code>__dataframe_namespace__() -&gt; dataframe_api_compat.pandas_standard.Namespace</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __dataframe_namespace__(\n    self,\n) -&gt; dataframe_api_compat.pandas_standard.Namespace:\n    return dataframe_api_compat.pandas_standard.Namespace(\n        api_version=self._api_version,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__divmod__","title":"<code>__divmod__(other: DataFrame | AnyScalar) -&gt; tuple[DataFrame, DataFrame]</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __divmod__(\n    self,\n    other: DataFrame | AnyScalar,\n) -&gt; tuple[DataFrame, DataFrame]:\n    _other = validate_comparand(self, other)\n    quotient, remainder = self.dataframe.__divmod__(_other)\n    return self._from_dataframe(quotient), self._from_dataframe(\n        remainder,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__eq__","title":"<code>__eq__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __eq__(self, other: AnyScalar) -&gt; DataFrame:  # type: ignore[override]\n    return self._from_dataframe(self.dataframe.__eq__(other))\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__floordiv__","title":"<code>__floordiv__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __floordiv__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.__floordiv__(_other),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__ge__","title":"<code>__ge__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __ge__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(self.dataframe.__ge__(other))\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__gt__","title":"<code>__gt__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __gt__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(self.dataframe.__gt__(other))\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__init__","title":"<code>__init__(dataframe: pd.DataFrame, *, api_version: str, is_persisted: bool = False) -&gt; None</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __init__(\n    self,\n    dataframe: pd.DataFrame,\n    *,\n    api_version: str,\n    is_persisted: bool = False,\n) -&gt; None:\n    self._is_persisted = is_persisted\n    self._validate_columns(dataframe.columns)\n    self._dataframe = dataframe.reset_index(drop=True)\n    self._api_version = api_version\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__invert__","title":"<code>__invert__() -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __invert__(self) -&gt; DataFrame:\n    self._validate_booleanness()\n    return self._from_dataframe(self.dataframe.__invert__())\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__iter__","title":"<code>__iter__() -&gt; NoReturn</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __iter__(self) -&gt; NoReturn:\n    raise NotImplementedError\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__le__","title":"<code>__le__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __le__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(self.dataframe.__le__(other))\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__lt__","title":"<code>__lt__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __lt__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(self.dataframe.__lt__(other))\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__mod__","title":"<code>__mod__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __mod__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.__mod__(other),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__mul__","title":"<code>__mul__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __mul__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.__mul__(_other),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__ne__","title":"<code>__ne__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __ne__(self, other: AnyScalar) -&gt; DataFrame:  # type: ignore[override]\n    return self._from_dataframe(self.dataframe.__ne__(other))\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__or__","title":"<code>__or__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __or__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(self.dataframe.__or__(_other))\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__pow__","title":"<code>__pow__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __pow__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.__pow__(_other),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__radd__","title":"<code>__radd__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __radd__(self, other: Column | AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self.__add__(_other)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__rand__","title":"<code>__rand__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __rand__(self, other: Column | AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self.__and__(_other)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__repr__","title":"<code>__repr__() -&gt; str</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __repr__(self) -&gt; str:  # pragma: no cover\n    header = f\" Standard DataFrame (api_version={self._api_version}) \"\n    length = len(header)\n    return (\n        \"\u250c\"\n        + \"\u2500\" * length\n        + \"\u2510\\n\"\n        + f\"|{header}|\\n\"\n        + \"| Add `.dataframe` to see native output         |\\n\"\n        + \"\u2514\"\n        + \"\u2500\" * length\n        + \"\u2518\\n\"\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__rfloordiv__","title":"<code>__rfloordiv__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __rfloordiv__(self, other: Column | AnyScalar) -&gt; DataFrame:  # pragma: no cover\n    _other = validate_comparand(self, other)\n    raise NotImplementedError\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__rmod__","title":"<code>__rmod__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __rmod__(self, other: Column | AnyScalar) -&gt; DataFrame:  # type: ignore[misc]  # pragma: no cover\n    _other = validate_comparand(self, other)\n    raise NotImplementedError\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__rmul__","title":"<code>__rmul__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __rmul__(self, other: Column | AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self.__mul__(_other)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__ror__","title":"<code>__ror__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __ror__(self, other: Column | AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self.__or__(_other)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__rpow__","title":"<code>__rpow__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __rpow__(self, other: Column | AnyScalar) -&gt; DataFrame:  # pragma: no cover\n    _other = validate_comparand(self, other)\n    raise NotImplementedError\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__rsub__","title":"<code>__rsub__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __rsub__(self, other: Column | AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return -1 * self.__sub__(_other)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__rtruediv__","title":"<code>__rtruediv__(other: Column | AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __rtruediv__(self, other: Column | AnyScalar) -&gt; DataFrame:  # pragma: no cover\n    _other = validate_comparand(self, other)\n    raise NotImplementedError\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__sub__","title":"<code>__sub__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __sub__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.__sub__(_other),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.__truediv__","title":"<code>__truediv__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def __truediv__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.__truediv__(_other),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.all","title":"<code>all(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def all(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    self._validate_booleanness()\n    return self._from_dataframe(\n        self.dataframe.all().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.any","title":"<code>any(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def any(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    self._validate_booleanness()\n    return self._from_dataframe(\n        self.dataframe.any().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.assign","title":"<code>assign(*columns: Column) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def assign(\n    self,\n    *columns: Column,\n) -&gt; DataFrame:\n    from dataframe_api_compat.pandas_standard.column_object import Column\n\n    df = self.dataframe.copy()  # TODO: remove defensive copy with CoW?\n    for column in columns:\n        if not isinstance(column, Column):\n            msg = f\"Expected iterable of Column, but the first element is: {type(column)}\"\n            raise TypeError(msg)\n        _series = validate_comparand(self, column)\n        df[_series.name] = _series\n    return self._from_dataframe(df)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.col","title":"<code>col(name: str) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def col(self, name: str) -&gt; Column:\n    from dataframe_api_compat.pandas_standard.column_object import Column\n\n    return Column(\n        self.dataframe.loc[:, name],\n        df=None if self._is_persisted else self,\n        api_version=self._api_version,\n        is_persisted=self._is_persisted,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.drop","title":"<code>drop(*labels: str) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def drop(self, *labels: str) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.drop(list(labels), axis=1),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.drop_nulls","title":"<code>drop_nulls(*, column_names: list[str] | None = None) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def drop_nulls(\n    self,\n    *,\n    column_names: list[str] | None = None,\n) -&gt; DataFrame:\n    namespace = self.__dataframe_namespace__()\n    mask = ~namespace.any_horizontal(\n        *[\n            self.col(col_name).is_null()\n            for col_name in column_names or self.column_names\n        ],\n    )\n    return self.filter(mask)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.fill_nan","title":"<code>fill_nan(value: float | Scalar | NullType) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def fill_nan(self, value: float | Scalar | NullType) -&gt; DataFrame:\n    _value = validate_comparand(self, value)\n    new_cols = {}\n    df = self.dataframe\n    for col in df.columns:\n        ser = df[col].copy()\n        if is_extension_array_dtype(ser.dtype):\n            if self.__dataframe_namespace__().is_null(_value):\n                ser[np.isnan(ser).fillna(False).to_numpy(bool)] = pd.NA\n            else:\n                ser[np.isnan(ser).fillna(False).to_numpy(bool)] = _value\n        else:\n            if self.__dataframe_namespace__().is_null(_value):\n                ser[np.isnan(ser).fillna(False).to_numpy(bool)] = np.nan\n            else:\n                ser[np.isnan(ser).fillna(False).to_numpy(bool)] = _value\n        new_cols[col] = ser\n    df = pd.DataFrame(new_cols)\n    return self._from_dataframe(df)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.fill_null","title":"<code>fill_null(value: AnyScalar, *, column_names: list[str] | None = None) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def fill_null(\n    self,\n    value: AnyScalar,\n    *,\n    column_names: list[str] | None = None,\n) -&gt; DataFrame:\n    if column_names is None:\n        column_names = self.dataframe.columns.tolist()\n    assert isinstance(column_names, list)  # help type checkers\n    return self.assign(\n        *[\n            col.fill_null(value)\n            for col in self.iter_columns()\n            if col.name in column_names\n        ],\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.filter","title":"<code>filter(mask: Column) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def filter(\n    self,\n    mask: Column,\n) -&gt; DataFrame:\n    _mask = validate_comparand(self, mask)\n    df = self.dataframe\n    df = df.loc[_mask]\n    return self._from_dataframe(df)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.get_column_names","title":"<code>get_column_names() -&gt; list[str]</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def get_column_names(self) -&gt; list[str]:\n    # DO NOT REMOVE\n    # This one is used in upstream tests - even if deprecated,\n    # just leave it in for backwards compatibility\n    return self.dataframe.columns.tolist()  # type: ignore[no-any-return]\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.take","title":"<code>take(indices: Column) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def take(\n    self,\n    indices: Column,\n) -&gt; DataFrame:\n    _indices = validate_comparand(self, indices)\n    return self._from_dataframe(\n        self.dataframe.iloc[_indices.to_list(), :],\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.group_by","title":"<code>group_by(*keys: str) -&gt; GroupBy</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def group_by(self, *keys: str) -&gt; GroupBy:\n    from dataframe_api_compat.pandas_standard.group_by_object import GroupBy\n\n    for key in keys:\n        if key not in self.column_names:\n            msg = f\"key {key} not present in DataFrame's columns\"\n            raise KeyError(msg)\n    return GroupBy(self, keys, api_version=self._api_version)\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.is_nan","title":"<code>is_nan() -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def is_nan(self) -&gt; DataFrame:\n    return self.assign(*[col.is_nan() for col in self.iter_columns()])\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.is_null","title":"<code>is_null(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def is_null(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    result: list[pd.Series] = []\n    for column in self.dataframe.columns:\n        result.append(self.dataframe[column].isna())\n    return self._from_dataframe(pd.concat(result, axis=1))\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.join","title":"<code>join(other: DataFrame, *, how: Literal['left', 'inner', 'outer'], left_on: str | list[str], right_on: str | list[str]) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def join(\n    self,\n    other: DataFrame,\n    *,\n    how: Literal[\"left\", \"inner\", \"outer\"],\n    left_on: str | list[str],\n    right_on: str | list[str],\n) -&gt; DataFrame:\n    if how not in [\"left\", \"inner\", \"outer\"]:\n        msg = f\"Expected 'left', 'inner', 'outer', got: {how}\"\n        raise ValueError(msg)\n\n    if isinstance(left_on, str):\n        left_on = [left_on]\n    if isinstance(right_on, str):\n        right_on = [right_on]\n\n    if overlap := (set(self.column_names) - set(left_on)).intersection(\n        set(other.column_names) - set(right_on),\n    ):\n        msg = f\"Found overlapping columns in join: {overlap}. Please rename columns to avoid this.\"\n        raise ValueError(msg)\n\n    return self._from_dataframe(\n        self.dataframe.merge(\n            other.dataframe,\n            left_on=left_on,\n            right_on=right_on,\n            how=how,\n        ),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.max","title":"<code>max(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def max(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.max().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.mean","title":"<code>mean(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def mean(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.mean().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.median","title":"<code>median(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def median(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.median().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.min","title":"<code>min(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def min(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.min().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.persist","title":"<code>persist() -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def persist(self) -&gt; DataFrame:\n    if self._is_persisted:\n        warnings.warn(\n            \"Calling `.persist` on DataFrame that was already persisted\",\n            UserWarning,\n            stacklevel=2,\n        )\n    return DataFrame(\n        self.dataframe,\n        api_version=self._api_version,\n        is_persisted=True,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.prod","title":"<code>prod(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def prod(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.prod().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.rename","title":"<code>rename(mapping: Mapping[str, str]) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def rename(self, mapping: Mapping[str, str]) -&gt; DataFrame:\n    if not isinstance(mapping, collections.abc.Mapping):\n        msg = f\"Expected Mapping, got: {type(mapping)}\"\n        raise TypeError(msg)\n    return self._from_dataframe(\n        self.dataframe.rename(columns=mapping),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.select","title":"<code>select(*columns: str) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def select(self, *columns: str) -&gt; DataFrame:\n    cols = list(columns)\n    if cols and isinstance(cols[0], (list, tuple)):\n        msg = f\"Expected iterable of column names, but the first element is: {type(cols[0])}\"\n        raise TypeError(msg)\n    return self._from_dataframe(\n        self.dataframe.loc[:, list(columns)],\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.shape","title":"<code>shape() -&gt; tuple[int, int]</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def shape(self) -&gt; tuple[int, int]:\n    df = self._validate_is_persisted()\n    return df.shape  # type: ignore[no-any-return]\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.slice_rows","title":"<code>slice_rows(start: int | None, stop: int | None, step: int | None) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def slice_rows(\n    self,\n    start: int | None,\n    stop: int | None,\n    step: int | None,\n) -&gt; DataFrame:\n    return self._from_dataframe(self.dataframe.iloc[start:stop:step])\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.sort","title":"<code>sort(*keys: str, ascending: Sequence[bool] | bool = True, nulls_position: Literal['first', 'last'] = 'last') -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def sort(\n    self,\n    *keys: str,\n    ascending: Sequence[bool] | bool = True,\n    nulls_position: Literal[\"first\", \"last\"] = \"last\",\n) -&gt; DataFrame:\n    if not keys:\n        keys = self.dataframe.columns.tolist()\n    df = self.dataframe\n    return self._from_dataframe(\n        df.sort_values(list(keys), ascending=ascending),\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.std","title":"<code>std(*, correction: float | Scalar | NullType = 1.0, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def std(\n    self,\n    *,\n    correction: float | Scalar | NullType = 1.0,\n    skip_nulls: bool | Scalar = True,\n) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.std().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.sum","title":"<code>sum(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def sum(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.sum().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.to_array","title":"<code>to_array(dtype: DType | None = None) -&gt; Any</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def to_array(self, dtype: DType | None = None) -&gt; Any:\n    self._validate_is_persisted()\n    return self.dataframe.to_numpy()\n</code></pre>"},{"location":"pandas-dataframe/#dataframe_api_compat.pandas_standard.DataFrame.var","title":"<code>var(*, correction: float | Scalar | NullType = 1.0, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/dataframe_object.py</code> <pre><code>def var(\n    self,\n    *,\n    correction: float | Scalar | NullType = 1.0,\n    skip_nulls: bool | Scalar = True,\n) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.var().to_frame().T,\n    )\n</code></pre>"},{"location":"pandas-namespace/","title":"Pandas Namespace","text":"<p>             Bases: <code>Namespace</code></p> Source code in <code>dataframe_api_compat/pandas_standard/__init__.py</code> <pre><code>class Namespace(NamespaceT):\n    def __init__(self, *, api_version: str) -&gt; None:\n        self.__dataframe_api_version__ = api_version\n        self._api_version = api_version\n\n    class Int64(Int64T):\n        ...\n\n    class Int32(Int32T):\n        ...\n\n    class Int16(Int16T):\n        ...\n\n    class Int8(Int8T):\n        ...\n\n    class UInt64(UInt64T):\n        ...\n\n    class UInt32(UInt32T):\n        ...\n\n    class UInt16(UInt16T):\n        ...\n\n    class UInt8(UInt8T):\n        ...\n\n    class Float64(Float64T):\n        ...\n\n    class Float32(Float32T):\n        ...\n\n    class Bool(BoolT):\n        ...\n\n    class String(StringT):\n        ...\n\n    class Date(DateT):\n        ...\n\n    class Datetime(DatetimeT):\n        def __init__(\n            self,\n            time_unit: Literal[\"ms\", \"us\"],\n            time_zone: str | None = None,\n        ) -&gt; None:\n            self.time_unit = time_unit\n            # TODO validate time zone\n            self.time_zone = time_zone\n\n    class Duration(DurationT):\n        def __init__(self, time_unit: Literal[\"ms\", \"us\"]) -&gt; None:\n            self.time_unit = time_unit\n\n    class NullType(NullTypeT):\n        ...\n\n    null = NullType()\n\n    def dataframe_from_columns(\n        self,\n        *columns: ColumnT,\n    ) -&gt; DataFrame:\n        data = {}\n        api_versions: set[str] = set()\n        for col in columns:\n            ser = col._materialise()  # type: ignore[attr-defined]\n            data[ser.name] = ser\n            api_versions.add(col._api_version)  # type: ignore[attr-defined]\n        return DataFrame(pd.DataFrame(data), api_version=list(api_versions)[0])\n\n    def column_from_1d_array(  # type: ignore[override]\n        self,\n        data: Any,\n        *,\n        name: str | None = None,\n    ) -&gt; Column:\n        ser = pd.Series(data, name=name)\n        return Column(ser, api_version=self._api_version, df=None, is_persisted=True)\n\n    def column_from_sequence(\n        self,\n        sequence: Sequence[Any],\n        *,\n        dtype: DType | None = None,\n        name: str = \"\",\n    ) -&gt; Column:\n        if dtype is not None:\n            ser = pd.Series(\n                sequence,\n                dtype=map_standard_dtype_to_pandas_dtype(dtype),\n                name=name,\n            )\n        else:\n            ser = pd.Series(sequence, name=name)\n        return Column(ser, api_version=self._api_version, df=None, is_persisted=True)\n\n    def concat(\n        self,\n        dataframes: Sequence[DataFrameT],\n    ) -&gt; DataFrame:\n        dataframes = cast(\"Sequence[DataFrame]\", dataframes)\n        dtypes = dataframes[0].dataframe.dtypes\n        dfs: list[pd.DataFrame] = []\n        api_versions: set[str] = set()\n        for df in dataframes:\n            try:\n                pd.testing.assert_series_equal(\n                    df.dataframe.dtypes,\n                    dtypes,\n                )\n            except AssertionError as exc:\n                msg = \"Expected matching columns\"\n                raise ValueError(msg) from exc\n            dfs.append(df.dataframe)\n            api_versions.add(df._api_version)\n        if len(api_versions) &gt; 1:  # pragma: no cover\n            msg = f\"Multiple api versions found: {api_versions}\"\n            raise ValueError(msg)\n        return DataFrame(\n            pd.concat(\n                dfs,\n                axis=0,\n                ignore_index=True,\n            ),\n            api_version=api_versions.pop(),\n        )\n\n    def dataframe_from_2d_array(\n        self,\n        data: Any,\n        *,\n        names: Sequence[str],\n    ) -&gt; DataFrame:\n        df = pd.DataFrame(data, columns=list(names))\n        return DataFrame(df, api_version=self._api_version)\n\n    def is_null(self, value: Any) -&gt; bool:\n        return value is self.null\n\n    def is_dtype(self, dtype: DType, kind: str | tuple[str, ...]) -&gt; bool:\n        if isinstance(kind, str):\n            kind = (kind,)\n        dtypes: set[Any] = set()\n        for _kind in kind:\n            if _kind == \"bool\":\n                dtypes.add(Namespace.Bool)\n            if _kind == \"signed integer\" or _kind == \"integral\" or _kind == \"numeric\":\n                dtypes |= {\n                    Namespace.Int64,\n                    Namespace.Int32,\n                    Namespace.Int16,\n                    Namespace.Int8,\n                }\n            if _kind == \"unsigned integer\" or _kind == \"integral\" or _kind == \"numeric\":\n                dtypes |= {\n                    Namespace.UInt64,\n                    Namespace.UInt32,\n                    Namespace.UInt16,\n                    Namespace.UInt8,\n                }\n            if _kind == \"floating\" or _kind == \"numeric\":\n                dtypes |= {Namespace.Float64, Namespace.Float32}\n            if _kind == \"string\":\n                dtypes.add(Namespace.String)\n        return isinstance(dtype, tuple(dtypes))\n\n    def date(self, year: int, month: int, day: int) -&gt; Scalar:\n        return Scalar(\n            pd.Timestamp(dt.date(year, month, day)),\n            api_version=self._api_version,\n            df=None,\n            is_persisted=True,\n        )\n\n    # --- horizontal reductions\n\n    def all_horizontal(self, *columns: ColumnT, skip_nulls: bool = True) -&gt; ColumnT:\n        return reduce(lambda x, y: x &amp; y, columns)\n\n    def any_horizontal(self, *columns: ColumnT, skip_nulls: bool = True) -&gt; ColumnT:\n        return reduce(lambda x, y: x | y, columns)\n\n    def sorted_indices(\n        self,\n        *columns: ColumnT,\n        ascending: Sequence[bool] | bool = True,\n        nulls_position: Literal[\"first\", \"last\"] = \"last\",\n    ) -&gt; Column:\n        raise NotImplementedError\n\n    def unique_indices(\n        self,\n        *columns: ColumnT,\n        skip_nulls: bool | ScalarT = True,\n    ) -&gt; Column:\n        raise NotImplementedError\n\n    class Aggregation(AggregationT):\n        def __init__(self, column_name: str, output_name: str, aggregation: str) -&gt; None:\n            self.column_name = column_name\n            self.output_name = output_name\n            self.aggregation = aggregation\n\n        def __repr__(self) -&gt; str:  # pragma: no cover\n            return f\"{self.__class__.__name__}({self.column_name!r}, {self.output_name!r}, {self.aggregation!r})\"\n\n        def _replace(self, **kwargs: str) -&gt; AggregationT:\n            return self.__class__(\n                column_name=kwargs.get(\"column_name\", self.column_name),\n                output_name=kwargs.get(\"output_name\", self.output_name),\n                aggregation=kwargs.get(\"aggregation\", self.aggregation),\n            )\n\n        def rename(self, name: str | ScalarT) -&gt; AggregationT:\n            return self.__class__(self.column_name, name, self.aggregation)  # type: ignore[arg-type]\n\n        @classmethod\n        def any(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"any\")\n\n        @classmethod\n        def all(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"all\")\n\n        @classmethod\n        def min(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"min\")\n\n        @classmethod\n        def max(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"max\")\n\n        @classmethod\n        def sum(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"sum\")\n\n        @classmethod\n        def prod(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"prod\")\n\n        @classmethod\n        def median(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"median\")\n\n        @classmethod\n        def mean(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"mean\")\n\n        @classmethod\n        def std(\n            cls: AggregationT,\n            column: str,\n            *,\n            correction: float | ScalarT | NullTypeT = 1,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"std\")\n\n        @classmethod\n        def var(\n            cls: AggregationT,\n            column: str,\n            *,\n            correction: float | ScalarT | NullTypeT = 1,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"var\")\n\n        @classmethod\n        def size(\n            cls: AggregationT,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(\"__placeholder__\", \"size\", \"size\")\n</code></pre>"},{"location":"pandas-namespace/#dataframe_api_compat.pandas_standard.Namespace.__init__","title":"<code>__init__(*, api_version: str) -&gt; None</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/__init__.py</code> <pre><code>def __init__(self, *, api_version: str) -&gt; None:\n    self.__dataframe_api_version__ = api_version\n    self._api_version = api_version\n</code></pre>"},{"location":"pandas-scalar/","title":"Pandas Scalar","text":"<p>             Bases: <code>Scalar</code></p> Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>class Scalar(ScalarT):\n    def __init__(\n        self,\n        value: Any,\n        api_version: str,\n        df: DataFrame | None,\n        *,\n        is_persisted: bool = False,\n    ) -&gt; None:\n        self._value = value\n        self._api_version = api_version\n        self._df = df\n        self._is_persisted = is_persisted\n        assert is_persisted ^ (df is not None)\n\n    def __scalar_namespace__(self) -&gt; Namespace:\n        from dataframe_api_compat.pandas_standard import Namespace\n\n        return Namespace(api_version=self._api_version)\n\n    def _from_scalar(self, scalar: Scalar) -&gt; Scalar:\n        return Scalar(\n            scalar,\n            df=self._df,\n            api_version=self._api_version,\n            is_persisted=self._is_persisted,\n        )\n\n    @property\n    def dtype(self) -&gt; DType:  # pragma: no cover  # todo\n        msg = \"dtype not yet implemented for Scalar\"\n        raise NotImplementedError(msg)\n\n    @property\n    def scalar(self) -&gt; Any:  # pragma: no cover  # todo\n        return self._value\n\n    @property\n    def parent_dataframe(self) -&gt; Any:  # pragma: no cover  # todo\n        return self._df\n\n    def _materialise(self) -&gt; Any:\n        if not self._is_persisted:\n            msg = \"Can't call __bool__ on Scalar. Please use .persist() first.\"\n            raise RuntimeError(msg)\n        return self._value\n\n    def persist(self) -&gt; Scalar:\n        if self._is_persisted:\n            warnings.warn(\n                \"Calling `.persist` on Scalar that was already persisted\",\n                UserWarning,\n                stacklevel=2,\n            )\n        return Scalar(\n            self._value,\n            df=None,\n            api_version=self._api_version,\n            is_persisted=True,\n        )\n\n    def __lt__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__lt__(other))\n\n    def __le__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__le__(other))\n\n    def __eq__(self, other: Any) -&gt; Scalar:  # type: ignore[override]\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__eq__(other))\n\n    def __ne__(self, other: Any) -&gt; Scalar:  # type: ignore[override]\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__ne__(other))\n\n    def __gt__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__gt__(other))\n\n    def __ge__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__ge__(other))\n\n    def __add__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__add__(other))\n\n    def __radd__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(other + self._value)\n\n    def __sub__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__sub__(other))\n\n    def __rsub__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(other - self._value)\n\n    def __mul__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__mul__(other))\n\n    def __rmul__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(other * self._value)\n\n    def __mod__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__mod__(other))\n\n    def __rmod__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(other % self._value)\n\n    def __pow__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__pow__(other))\n\n    def __rpow__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(other**self._value)\n\n    def __floordiv__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__floordiv__(other))\n\n    def __rfloordiv__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(other // self._value)\n\n    def __truediv__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(self._value.__truediv__(other))\n\n    def __rtruediv__(self, other: Any) -&gt; Scalar:\n        other = validate_comparand(self, other)\n        if other is NotImplemented:\n            return NotImplemented\n        return self._from_scalar(other / self._value)\n\n    def __neg__(self) -&gt; Scalar:\n        return self._from_scalar(self._value.__neg__())\n\n    def __abs__(self) -&gt; Scalar:\n        return self._from_scalar(self._value.__abs__())\n\n    def __bool__(self) -&gt; bool:\n        return self._materialise().__bool__()  # type: ignore[no-any-return]\n\n    def __int__(self) -&gt; int:\n        return self._materialise().__int__()  # type: ignore[no-any-return]\n\n    def __float__(self) -&gt; float:\n        return self._materialise().__float__()  # type: ignore[no-any-return]\n\n    def __repr__(self) -&gt; str:  # pragma: no cover\n        header = f\" Standard Scalar (api_version={self._api_version}) \"\n        length = len(header)\n        return (\n            \"\u250c\"\n            + \"\u2500\" * length\n            + \"\u2510\\n\"\n            + f\"|{header}|\\n\"\n            + \"| Add `.scalar` to see native output         |\\n\"\n            + \"\u2514\"\n            + \"\u2500\" * length\n            + \"\u2518\\n\"\n        )\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.dtype","title":"<code>dtype: DType</code>  <code>property</code>","text":""},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__abs__","title":"<code>__abs__() -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __abs__(self) -&gt; Scalar:\n    return self._from_scalar(self._value.__abs__())\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__add__","title":"<code>__add__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __add__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__add__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__bool__","title":"<code>__bool__() -&gt; bool</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __bool__(self) -&gt; bool:\n    return self._materialise().__bool__()  # type: ignore[no-any-return]\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__eq__","title":"<code>__eq__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __eq__(self, other: Any) -&gt; Scalar:  # type: ignore[override]\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__eq__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__float__","title":"<code>__float__() -&gt; float</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __float__(self) -&gt; float:\n    return self._materialise().__float__()  # type: ignore[no-any-return]\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__floordiv__","title":"<code>__floordiv__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __floordiv__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__floordiv__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__ge__","title":"<code>__ge__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __ge__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__ge__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__gt__","title":"<code>__gt__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __gt__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__gt__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__init__","title":"<code>__init__(value: Any, api_version: str, df: DataFrame | None, *, is_persisted: bool = False) -&gt; None</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __init__(\n    self,\n    value: Any,\n    api_version: str,\n    df: DataFrame | None,\n    *,\n    is_persisted: bool = False,\n) -&gt; None:\n    self._value = value\n    self._api_version = api_version\n    self._df = df\n    self._is_persisted = is_persisted\n    assert is_persisted ^ (df is not None)\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__int__","title":"<code>__int__() -&gt; int</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __int__(self) -&gt; int:\n    return self._materialise().__int__()  # type: ignore[no-any-return]\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__le__","title":"<code>__le__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __le__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__le__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__lt__","title":"<code>__lt__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __lt__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__lt__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__mod__","title":"<code>__mod__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __mod__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__mod__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__mul__","title":"<code>__mul__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __mul__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__mul__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__ne__","title":"<code>__ne__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __ne__(self, other: Any) -&gt; Scalar:  # type: ignore[override]\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__ne__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__neg__","title":"<code>__neg__() -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __neg__(self) -&gt; Scalar:\n    return self._from_scalar(self._value.__neg__())\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__pow__","title":"<code>__pow__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __pow__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__pow__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__radd__","title":"<code>__radd__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __radd__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(other + self._value)\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__repr__","title":"<code>__repr__() -&gt; str</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __repr__(self) -&gt; str:  # pragma: no cover\n    header = f\" Standard Scalar (api_version={self._api_version}) \"\n    length = len(header)\n    return (\n        \"\u250c\"\n        + \"\u2500\" * length\n        + \"\u2510\\n\"\n        + f\"|{header}|\\n\"\n        + \"| Add `.scalar` to see native output         |\\n\"\n        + \"\u2514\"\n        + \"\u2500\" * length\n        + \"\u2518\\n\"\n    )\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__rfloordiv__","title":"<code>__rfloordiv__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __rfloordiv__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(other // self._value)\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__rmod__","title":"<code>__rmod__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __rmod__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(other % self._value)\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__rmul__","title":"<code>__rmul__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __rmul__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(other * self._value)\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__rpow__","title":"<code>__rpow__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __rpow__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(other**self._value)\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__rsub__","title":"<code>__rsub__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __rsub__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(other - self._value)\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__rtruediv__","title":"<code>__rtruediv__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __rtruediv__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(other / self._value)\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__sub__","title":"<code>__sub__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __sub__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__sub__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.__truediv__","title":"<code>__truediv__(other: Any) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def __truediv__(self, other: Any) -&gt; Scalar:\n    other = validate_comparand(self, other)\n    if other is NotImplemented:\n        return NotImplemented\n    return self._from_scalar(self._value.__truediv__(other))\n</code></pre>"},{"location":"pandas-scalar/#dataframe_api_compat.pandas_standard.Scalar.persist","title":"<code>persist() -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/scalar_object.py</code> <pre><code>def persist(self) -&gt; Scalar:\n    if self._is_persisted:\n        warnings.warn(\n            \"Calling `.persist` on Scalar that was already persisted\",\n            UserWarning,\n            stacklevel=2,\n        )\n    return Scalar(\n        self._value,\n        df=None,\n        api_version=self._api_version,\n        is_persisted=True,\n    )\n</code></pre>"},{"location":"polars-column/","title":"Polars Column","text":"<p>             Bases: <code>Column</code></p> Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>class Column(ColumnT):\n    def __init__(\n        self,\n        expr: pl.Expr | pl.Series,\n        *,\n        df: DataFrame | None,\n        api_version: str,\n        is_persisted: bool = False,\n    ) -&gt; None:\n        self._expr = expr\n        self._name = _extract_name(expr, df)\n        self._df = df\n        self._api_version = api_version\n        self._is_persisted = is_persisted\n        assert is_persisted ^ (df is not None)\n        assert is_persisted ^ isinstance(expr, pl.Expr)\n\n    def __repr__(self) -&gt; str:  # pragma: no cover\n        header = f\" Standard Column (api_version={self._api_version}) \"\n        length = len(header)\n        return (\n            \"\u250c\"\n            + \"\u2500\" * length\n            + \"\u2510\\n\"\n            + f\"|{header}|\\n\"\n            + \"| Add `.column` to see native output         |\\n\"\n            + \"\u2514\"\n            + \"\u2500\" * length\n            + \"\u2518\\n\"\n        )\n\n    def __iter__(self) -&gt; NoReturn:\n        raise NotImplementedError\n\n    def _from_expr(self, expr: pl.Expr | pl.Series) -&gt; Self:\n        return self.__class__(\n            expr,\n            df=self._df,\n            api_version=self._api_version,\n            is_persisted=self._is_persisted,\n        )\n\n    def _materialise(self) -&gt; pl.Series:\n        if not self._is_persisted:\n            msg = \"Column is not persisted, please call `.persist()` first.\\nNote: `persist` forces computation, use it with care, only when you need to,\\nand as late and little as possible.\"\n            raise RuntimeError(\n                msg,\n            )\n        return self._expr  # type: ignore[return-value]\n\n    # In the standard\n    def __column_namespace__(self) -&gt; Namespace:  # pragma: no cover\n        import dataframe_api_compat\n\n        return dataframe_api_compat.polars_standard.Namespace(\n            api_version=self._api_version,\n        )\n\n    def _to_scalar(self, value: Any) -&gt; Scalar:\n        from dataframe_api_compat.polars_standard.scalar_object import Scalar\n\n        return Scalar(\n            value,\n            api_version=self._api_version,\n            df=self._df,\n            is_persisted=self._is_persisted,\n        )\n\n    def persist(self) -&gt; Column:\n        if self._df is not None:\n            assert isinstance(self._df.dataframe, pl.LazyFrame)  # help mypy\n            df = self._df.dataframe.select(self._expr).collect()\n        else:\n            warnings.warn(\n                \"Calling `.persist` on Column that was already persisted\",\n                UserWarning,\n                stacklevel=2,\n            )\n            df = pl.select(self._expr)\n        column = df.get_column(df.columns[0])\n        return Column(\n            column,\n            df=None,\n            api_version=self._api_version,\n            is_persisted=True,\n        )\n\n    @property\n    def name(self) -&gt; str:\n        return self._name\n\n    @property\n    def column(self) -&gt; pl.Expr | pl.Series:\n        return self._expr\n\n    @property\n    def dtype(self) -&gt; DType:\n        from dataframe_api_compat.polars_standard import (\n            map_polars_dtype_to_standard_dtype,\n        )\n\n        if self._df is not None:\n            dtype = self._df.dataframe.select(self._expr).schema[self.name]\n        else:\n            dtype = pl.select(self._expr).schema[self.name]\n        return map_polars_dtype_to_standard_dtype(dtype)\n\n    @property\n    def parent_dataframe(self) -&gt; DataFrame | None:\n        return self._df\n\n    def take(self, indices: Column) -&gt; Column:\n        if Version(\"0.19.14\") &gt; POLARS_VERSION:\n            return self._from_expr(self._expr.take(indices._expr))\n        return self._from_expr(self._expr.gather(indices._expr))\n\n    def filter(self, mask: Column) -&gt; Column:\n        return self._from_expr(self._expr.filter(mask._expr))  # type: ignore[arg-type]\n\n    def get_value(self, row_number: int) -&gt; Any:\n        if Version(\"0.19.14\") &gt; POLARS_VERSION:\n            result = self._expr.take(row_number)\n        else:\n            result = self._expr.gather(row_number)\n        if isinstance(result, pl.Series):\n            return self._to_scalar(result.item())\n        return self._to_scalar(result)\n\n    def slice_rows(\n        self,\n        start: int | None,\n        stop: int | None,\n        step: int | None,\n    ) -&gt; Column:\n        if start is None:\n            start = 0\n        length = None if stop is None else stop - start\n        if step is None:\n            step = 1\n        if Version(\"0.19.14\") &gt; POLARS_VERSION:\n            return self._from_expr(self._expr.slice(start, length).take_every(step))\n        return self._from_expr(self._expr.slice(start, length).gather_every(step))\n\n    # Binary comparisons\n\n    def __eq__(self, other: Column | Any) -&gt; Column:  # type: ignore[override]\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr == other)\n\n    def __ne__(self, other: Column | Any) -&gt; Column:  # type: ignore[override]\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr != other)\n\n    def __ge__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr &gt;= other)\n\n    def __gt__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr &gt; other)\n\n    def __le__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr &lt;= other)\n\n    def __lt__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr &lt; other)\n\n    def __mul__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        res = self._expr * other\n        return self._from_expr(res)\n\n    def __rmul__(self, other: Column | Any) -&gt; Column:\n        return self.__mul__(other)\n\n    def __floordiv__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr // other)\n\n    def __rfloordiv__(self, other: Column | Any) -&gt; Column:\n        raise NotImplementedError\n\n    def __truediv__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        res = self._expr / other\n        return self._from_expr(res)\n\n    def __rtruediv__(self, other: Column | Any) -&gt; Column:\n        raise NotImplementedError\n\n    def __pow__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        ret = self._expr.pow(other)\n        return self._from_expr(ret)\n\n    def __rpow__(self, other: Column | Any) -&gt; Column:  # pragma: no cover\n        raise NotImplementedError\n\n    def __mod__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr % other)\n\n    def __rmod__(self, other: Column | Any) -&gt; Column:\n        raise NotImplementedError\n\n    def __divmod__(\n        self,\n        other: Column | Any,\n    ) -&gt; tuple[Column, Column]:\n        # validation happens in the deferred calls anyway\n        quotient = self // other\n        remainder = self - quotient * other\n        return quotient, remainder\n\n    def __and__(\n        self,\n        other: Self | bool | Scalar,\n    ) -&gt; Self:\n        _other = validate_comparand(self, other)\n        return self._from_expr(self._expr &amp; _other)\n\n    def __rand__(\n        self,\n        other: Column | Any | Scalar,\n    ) -&gt; Column:\n        return self.__and__(other)\n\n    def __or__(\n        self,\n        other: Self | bool | Scalar,\n    ) -&gt; Self:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr | other)  # type: ignore[operator, arg-type]\n\n    def __ror__(self, other: Column | Any | Scalar) -&gt; Column:\n        return self.__or__(other)\n\n    def __add__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr + other)\n\n    def __radd__(self, other: Column | Any) -&gt; Column:\n        return self.__add__(other)\n\n    def __sub__(self, other: Column | Any) -&gt; Column:\n        other = validate_comparand(self, other)\n        return self._from_expr(self._expr - other)\n\n    def __rsub__(self, other: Column | Any) -&gt; Column:\n        return -1 * self.__sub__(other)\n\n    # Unary\n\n    def __invert__(self) -&gt; Column:\n        return self._from_expr(~self._expr)\n\n    # Reductions\n\n    def any(self, *, skip_nulls: bool | Scalar = True) -&gt; Scalar:\n        return self._to_scalar(self._expr.any())\n\n    def all(self, *, skip_nulls: bool | Scalar = True) -&gt; Scalar:\n        return self._to_scalar(self._expr.all())\n\n    def min(\n        self,\n        *,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Scalar:\n        return self._to_scalar(self._expr.min())\n\n    def max(\n        self,\n        *,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Scalar:\n        return self._to_scalar(self._expr.max())\n\n    def sum(\n        self,\n        *,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Scalar:\n        return self._to_scalar(self._expr.sum())\n\n    def prod(\n        self,\n        *,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Scalar:\n        return self._to_scalar(self._expr.product())\n\n    def mean(\n        self,\n        *,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Scalar:\n        return self._to_scalar(self._expr.mean())\n\n    def median(\n        self,\n        *,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Scalar:\n        return self._to_scalar(self._expr.median())\n\n    def std(\n        self,\n        *,\n        correction: float | Scalar = 1.0,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Scalar:\n        return self._to_scalar(self._expr.std())\n\n    def var(\n        self,\n        *,\n        correction: float | Scalar | NullType = 1.0,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Scalar:\n        return self._to_scalar(self._expr.var())\n\n    def len(self) -&gt; Scalar:\n        return self._to_scalar(self._expr.len())\n\n    def n_unique(self, *, skip_nulls: bool = True) -&gt; Scalar:\n        return self._to_scalar(self._expr.n_unique())\n\n    # Transformations\n\n    def is_null(self) -&gt; Self:\n        return self._from_expr(self._expr.is_null())\n\n    def is_nan(self) -&gt; Column:\n        return self._from_expr(self._expr.is_nan())\n\n    def sort(\n        self,\n        *,\n        ascending: bool = True,\n        nulls_position: Literal[\"first\", \"last\"] = \"last\",\n    ) -&gt; Column:\n        expr = self._expr.sort(descending=not ascending)\n        return self._from_expr(expr)\n\n    def is_in(self, values: Self) -&gt; Self:\n        return self._from_expr(self._expr.is_in(values._expr))  # type: ignore[arg-type]\n\n    def sorted_indices(\n        self,\n        *,\n        ascending: bool = True,\n        nulls_position: Literal[\"first\", \"last\"] = \"last\",\n    ) -&gt; Column:\n        expr = self._expr.arg_sort(descending=not ascending)\n        return self._from_expr(expr)\n\n    def unique_indices(\n        self,\n        *,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; Self:\n        raise NotImplementedError\n\n    def fill_nan(\n        self,\n        value: float | NullType | Scalar,\n    ) -&gt; Column:\n        _value = validate_comparand(self, value)\n        if isinstance(_value, self.__column_namespace__().NullType):\n            return self._from_expr(self._expr.fill_nan(pl.lit(None)))\n        return self._from_expr(self._expr.fill_nan(_value))\n\n    def fill_null(self, value: Any) -&gt; Column:\n        value = validate_comparand(self, value)\n        return self._from_expr(self._expr.fill_null(value))\n\n    def cumulative_sum(self, *, skip_nulls: bool | Scalar = True) -&gt; Column:\n        if Version(\"0.19.14\") &gt; POLARS_VERSION:\n            return self._from_expr(self._expr.cumsum())\n        return self._from_expr(self._expr.cum_sum())\n\n    def cumulative_prod(self, *, skip_nulls: bool | Scalar = True) -&gt; Column:\n        if Version(\"0.19.14\") &gt; POLARS_VERSION:\n            return self._from_expr(self._expr.cumprod())\n        return self._from_expr(self._expr.cum_prod())\n\n    def cumulative_max(self, *, skip_nulls: bool | Scalar = True) -&gt; Column:\n        if Version(\"0.19.14\") &gt; POLARS_VERSION:\n            return self._from_expr(self._expr.cummax())\n        return self._from_expr(self._expr.cum_max())\n\n    def cumulative_min(self, *, skip_nulls: bool | Scalar = True) -&gt; Column:\n        if Version(\"0.19.14\") &gt; POLARS_VERSION:\n            return self._from_expr(self._expr.cummin())\n        return self._from_expr(self._expr.cum_min())\n\n    def rename(self, name: str | Scalar) -&gt; Column:\n        _name = validate_comparand(self, name)\n        return self._from_expr(self._expr.alias(_name))\n\n    def shift(self, offset: int | Scalar) -&gt; Column:\n        _offset = validate_comparand(self, offset)\n        return self._from_expr(self._expr.shift(_offset))\n\n    # Conversions\n\n    def to_array(self) -&gt; Any:\n        ser = self._materialise()\n        return ser.to_numpy()\n\n    def cast(self, dtype: DType) -&gt; Column:\n        from dataframe_api_compat.polars_standard import _map_standard_to_polars_dtypes\n\n        polars_dtype = _map_standard_to_polars_dtypes(\n            dtype,\n        )\n        return self._from_expr(self._expr.cast(polars_dtype))\n\n    # --- temporal methods ---\n\n    def year(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.year())\n\n    def month(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.month())\n\n    def day(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.day())\n\n    def hour(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.hour())\n\n    def minute(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.minute())\n\n    def second(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.second())\n\n    def microsecond(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.microsecond())\n\n    def nanosecond(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.nanosecond())\n\n    def iso_weekday(self) -&gt; Column:\n        return self._from_expr(self._expr.dt.weekday())\n\n    def floor(self, frequency: str) -&gt; Column:\n        frequency = (\n            frequency.replace(\"day\", \"d\")\n            .replace(\"hour\", \"h\")\n            .replace(\"minute\", \"m\")\n            .replace(\"second\", \"s\")\n            .replace(\"millisecond\", \"ms\")\n            .replace(\"microsecond\", \"us\")\n            .replace(\"nanosecond\", \"ns\")\n        )\n        return self._from_expr(self._expr.dt.truncate(frequency))\n\n    def unix_timestamp(\n        self,\n        *,\n        time_unit: str | Scalar = \"s\",\n    ) -&gt; Column:\n        _time_unit = validate_comparand(self, time_unit)\n        if _time_unit != \"s\":\n            return self._from_expr(self._expr.dt.timestamp(time_unit=_time_unit))\n        return self._from_expr(self._expr.dt.timestamp(time_unit=\"ms\") // 1000)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.column","title":"<code>column: pl.Expr | pl.Series</code>  <code>property</code>","text":""},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.dtype","title":"<code>dtype: DType</code>  <code>property</code>","text":""},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.name","title":"<code>name: str</code>  <code>property</code>","text":""},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.parent_dataframe","title":"<code>parent_dataframe: DataFrame | None</code>  <code>property</code>","text":""},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__add__","title":"<code>__add__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __add__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr + other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__and__","title":"<code>__and__(other: Self | bool | Scalar) -&gt; Self</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __and__(\n    self,\n    other: Self | bool | Scalar,\n) -&gt; Self:\n    _other = validate_comparand(self, other)\n    return self._from_expr(self._expr &amp; _other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__column_namespace__","title":"<code>__column_namespace__() -&gt; Namespace</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __column_namespace__(self) -&gt; Namespace:  # pragma: no cover\n    import dataframe_api_compat\n\n    return dataframe_api_compat.polars_standard.Namespace(\n        api_version=self._api_version,\n    )\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__divmod__","title":"<code>__divmod__(other: Column | Any) -&gt; tuple[Column, Column]</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __divmod__(\n    self,\n    other: Column | Any,\n) -&gt; tuple[Column, Column]:\n    # validation happens in the deferred calls anyway\n    quotient = self // other\n    remainder = self - quotient * other\n    return quotient, remainder\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__eq__","title":"<code>__eq__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __eq__(self, other: Column | Any) -&gt; Column:  # type: ignore[override]\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr == other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__floordiv__","title":"<code>__floordiv__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __floordiv__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr // other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__ge__","title":"<code>__ge__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __ge__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr &gt;= other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__gt__","title":"<code>__gt__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __gt__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr &gt; other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__init__","title":"<code>__init__(expr: pl.Expr | pl.Series, *, df: DataFrame | None, api_version: str, is_persisted: bool = False) -&gt; None</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __init__(\n    self,\n    expr: pl.Expr | pl.Series,\n    *,\n    df: DataFrame | None,\n    api_version: str,\n    is_persisted: bool = False,\n) -&gt; None:\n    self._expr = expr\n    self._name = _extract_name(expr, df)\n    self._df = df\n    self._api_version = api_version\n    self._is_persisted = is_persisted\n    assert is_persisted ^ (df is not None)\n    assert is_persisted ^ isinstance(expr, pl.Expr)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__invert__","title":"<code>__invert__() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __invert__(self) -&gt; Column:\n    return self._from_expr(~self._expr)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__iter__","title":"<code>__iter__() -&gt; NoReturn</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __iter__(self) -&gt; NoReturn:\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__le__","title":"<code>__le__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __le__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr &lt;= other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__lt__","title":"<code>__lt__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __lt__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr &lt; other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__mod__","title":"<code>__mod__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __mod__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr % other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__mul__","title":"<code>__mul__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __mul__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    res = self._expr * other\n    return self._from_expr(res)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__ne__","title":"<code>__ne__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __ne__(self, other: Column | Any) -&gt; Column:  # type: ignore[override]\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr != other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__or__","title":"<code>__or__(other: Self | bool | Scalar) -&gt; Self</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __or__(\n    self,\n    other: Self | bool | Scalar,\n) -&gt; Self:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr | other)  # type: ignore[operator, arg-type]\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__pow__","title":"<code>__pow__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __pow__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    ret = self._expr.pow(other)\n    return self._from_expr(ret)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__radd__","title":"<code>__radd__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __radd__(self, other: Column | Any) -&gt; Column:\n    return self.__add__(other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__rand__","title":"<code>__rand__(other: Column | Any | Scalar) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __rand__(\n    self,\n    other: Column | Any | Scalar,\n) -&gt; Column:\n    return self.__and__(other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__repr__","title":"<code>__repr__() -&gt; str</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __repr__(self) -&gt; str:  # pragma: no cover\n    header = f\" Standard Column (api_version={self._api_version}) \"\n    length = len(header)\n    return (\n        \"\u250c\"\n        + \"\u2500\" * length\n        + \"\u2510\\n\"\n        + f\"|{header}|\\n\"\n        + \"| Add `.column` to see native output         |\\n\"\n        + \"\u2514\"\n        + \"\u2500\" * length\n        + \"\u2518\\n\"\n    )\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__rfloordiv__","title":"<code>__rfloordiv__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __rfloordiv__(self, other: Column | Any) -&gt; Column:\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__rmod__","title":"<code>__rmod__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __rmod__(self, other: Column | Any) -&gt; Column:\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__rmul__","title":"<code>__rmul__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __rmul__(self, other: Column | Any) -&gt; Column:\n    return self.__mul__(other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__ror__","title":"<code>__ror__(other: Column | Any | Scalar) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __ror__(self, other: Column | Any | Scalar) -&gt; Column:\n    return self.__or__(other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__rpow__","title":"<code>__rpow__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __rpow__(self, other: Column | Any) -&gt; Column:  # pragma: no cover\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__rsub__","title":"<code>__rsub__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __rsub__(self, other: Column | Any) -&gt; Column:\n    return -1 * self.__sub__(other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__rtruediv__","title":"<code>__rtruediv__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __rtruediv__(self, other: Column | Any) -&gt; Column:\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__sub__","title":"<code>__sub__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __sub__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    return self._from_expr(self._expr - other)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.__truediv__","title":"<code>__truediv__(other: Column | Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def __truediv__(self, other: Column | Any) -&gt; Column:\n    other = validate_comparand(self, other)\n    res = self._expr / other\n    return self._from_expr(res)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.all","title":"<code>all(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def all(self, *, skip_nulls: bool | Scalar = True) -&gt; Scalar:\n    return self._to_scalar(self._expr.all())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.any","title":"<code>any(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def any(self, *, skip_nulls: bool | Scalar = True) -&gt; Scalar:\n    return self._to_scalar(self._expr.any())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.cumulative_max","title":"<code>cumulative_max(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def cumulative_max(self, *, skip_nulls: bool | Scalar = True) -&gt; Column:\n    if Version(\"0.19.14\") &gt; POLARS_VERSION:\n        return self._from_expr(self._expr.cummax())\n    return self._from_expr(self._expr.cum_max())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.cumulative_min","title":"<code>cumulative_min(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def cumulative_min(self, *, skip_nulls: bool | Scalar = True) -&gt; Column:\n    if Version(\"0.19.14\") &gt; POLARS_VERSION:\n        return self._from_expr(self._expr.cummin())\n    return self._from_expr(self._expr.cum_min())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.cumulative_prod","title":"<code>cumulative_prod(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def cumulative_prod(self, *, skip_nulls: bool | Scalar = True) -&gt; Column:\n    if Version(\"0.19.14\") &gt; POLARS_VERSION:\n        return self._from_expr(self._expr.cumprod())\n    return self._from_expr(self._expr.cum_prod())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.cumulative_sum","title":"<code>cumulative_sum(*, skip_nulls: bool | Scalar = True) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def cumulative_sum(self, *, skip_nulls: bool | Scalar = True) -&gt; Column:\n    if Version(\"0.19.14\") &gt; POLARS_VERSION:\n        return self._from_expr(self._expr.cumsum())\n    return self._from_expr(self._expr.cum_sum())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.day","title":"<code>day() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def day(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.day())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.fill_nan","title":"<code>fill_nan(value: float | NullType | Scalar) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def fill_nan(\n    self,\n    value: float | NullType | Scalar,\n) -&gt; Column:\n    _value = validate_comparand(self, value)\n    if isinstance(_value, self.__column_namespace__().NullType):\n        return self._from_expr(self._expr.fill_nan(pl.lit(None)))\n    return self._from_expr(self._expr.fill_nan(_value))\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.fill_null","title":"<code>fill_null(value: Any) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def fill_null(self, value: Any) -&gt; Column:\n    value = validate_comparand(self, value)\n    return self._from_expr(self._expr.fill_null(value))\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.filter","title":"<code>filter(mask: Column) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def filter(self, mask: Column) -&gt; Column:\n    return self._from_expr(self._expr.filter(mask._expr))  # type: ignore[arg-type]\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.floor","title":"<code>floor(frequency: str) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def floor(self, frequency: str) -&gt; Column:\n    frequency = (\n        frequency.replace(\"day\", \"d\")\n        .replace(\"hour\", \"h\")\n        .replace(\"minute\", \"m\")\n        .replace(\"second\", \"s\")\n        .replace(\"millisecond\", \"ms\")\n        .replace(\"microsecond\", \"us\")\n        .replace(\"nanosecond\", \"ns\")\n    )\n    return self._from_expr(self._expr.dt.truncate(frequency))\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.take","title":"<code>take(indices: Column) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def take(self, indices: Column) -&gt; Column:\n    if Version(\"0.19.14\") &gt; POLARS_VERSION:\n        return self._from_expr(self._expr.take(indices._expr))\n    return self._from_expr(self._expr.gather(indices._expr))\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.get_value","title":"<code>get_value(row_number: int) -&gt; Any</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def get_value(self, row_number: int) -&gt; Any:\n    if Version(\"0.19.14\") &gt; POLARS_VERSION:\n        result = self._expr.take(row_number)\n    else:\n        result = self._expr.gather(row_number)\n    if isinstance(result, pl.Series):\n        return self._to_scalar(result.item())\n    return self._to_scalar(result)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.hour","title":"<code>hour() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def hour(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.hour())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.is_in","title":"<code>is_in(values: Self) -&gt; Self</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def is_in(self, values: Self) -&gt; Self:\n    return self._from_expr(self._expr.is_in(values._expr))  # type: ignore[arg-type]\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.is_nan","title":"<code>is_nan() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def is_nan(self) -&gt; Column:\n    return self._from_expr(self._expr.is_nan())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.is_null","title":"<code>is_null() -&gt; Self</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def is_null(self) -&gt; Self:\n    return self._from_expr(self._expr.is_null())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.iso_weekday","title":"<code>iso_weekday() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def iso_weekday(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.weekday())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.max","title":"<code>max(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def max(\n    self,\n    *,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Scalar:\n    return self._to_scalar(self._expr.max())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.mean","title":"<code>mean(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def mean(\n    self,\n    *,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Scalar:\n    return self._to_scalar(self._expr.mean())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.median","title":"<code>median(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def median(\n    self,\n    *,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Scalar:\n    return self._to_scalar(self._expr.median())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.microsecond","title":"<code>microsecond() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def microsecond(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.microsecond())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.min","title":"<code>min(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def min(\n    self,\n    *,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Scalar:\n    return self._to_scalar(self._expr.min())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.minute","title":"<code>minute() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def minute(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.minute())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.month","title":"<code>month() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def month(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.month())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.nanosecond","title":"<code>nanosecond() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def nanosecond(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.nanosecond())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.persist","title":"<code>persist() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def persist(self) -&gt; Column:\n    if self._df is not None:\n        assert isinstance(self._df.dataframe, pl.LazyFrame)  # help mypy\n        df = self._df.dataframe.select(self._expr).collect()\n    else:\n        warnings.warn(\n            \"Calling `.persist` on Column that was already persisted\",\n            UserWarning,\n            stacklevel=2,\n        )\n        df = pl.select(self._expr)\n    column = df.get_column(df.columns[0])\n    return Column(\n        column,\n        df=None,\n        api_version=self._api_version,\n        is_persisted=True,\n    )\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.prod","title":"<code>prod(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def prod(\n    self,\n    *,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Scalar:\n    return self._to_scalar(self._expr.product())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.rename","title":"<code>rename(name: str | Scalar) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def rename(self, name: str | Scalar) -&gt; Column:\n    _name = validate_comparand(self, name)\n    return self._from_expr(self._expr.alias(_name))\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.second","title":"<code>second() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def second(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.second())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.shift","title":"<code>shift(offset: int | Scalar) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def shift(self, offset: int | Scalar) -&gt; Column:\n    _offset = validate_comparand(self, offset)\n    return self._from_expr(self._expr.shift(_offset))\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.slice_rows","title":"<code>slice_rows(start: int | None, stop: int | None, step: int | None) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def slice_rows(\n    self,\n    start: int | None,\n    stop: int | None,\n    step: int | None,\n) -&gt; Column:\n    if start is None:\n        start = 0\n    length = None if stop is None else stop - start\n    if step is None:\n        step = 1\n    if Version(\"0.19.14\") &gt; POLARS_VERSION:\n        return self._from_expr(self._expr.slice(start, length).take_every(step))\n    return self._from_expr(self._expr.slice(start, length).gather_every(step))\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.sort","title":"<code>sort(*, ascending: bool = True, nulls_position: Literal['first', 'last'] = 'last') -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def sort(\n    self,\n    *,\n    ascending: bool = True,\n    nulls_position: Literal[\"first\", \"last\"] = \"last\",\n) -&gt; Column:\n    expr = self._expr.sort(descending=not ascending)\n    return self._from_expr(expr)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.sorted_indices","title":"<code>sorted_indices(*, ascending: bool = True, nulls_position: Literal['first', 'last'] = 'last') -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def sorted_indices(\n    self,\n    *,\n    ascending: bool = True,\n    nulls_position: Literal[\"first\", \"last\"] = \"last\",\n) -&gt; Column:\n    expr = self._expr.arg_sort(descending=not ascending)\n    return self._from_expr(expr)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.std","title":"<code>std(*, correction: float | Scalar = 1.0, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def std(\n    self,\n    *,\n    correction: float | Scalar = 1.0,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Scalar:\n    return self._to_scalar(self._expr.std())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.sum","title":"<code>sum(*, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def sum(\n    self,\n    *,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Scalar:\n    return self._to_scalar(self._expr.sum())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.to_array","title":"<code>to_array() -&gt; Any</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def to_array(self) -&gt; Any:\n    ser = self._materialise()\n    return ser.to_numpy()\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.unique_indices","title":"<code>unique_indices(*, skip_nulls: bool | Scalar = True) -&gt; Self</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def unique_indices(\n    self,\n    *,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Self:\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.unix_timestamp","title":"<code>unix_timestamp(*, time_unit: str | Scalar = 's') -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def unix_timestamp(\n    self,\n    *,\n    time_unit: str | Scalar = \"s\",\n) -&gt; Column:\n    _time_unit = validate_comparand(self, time_unit)\n    if _time_unit != \"s\":\n        return self._from_expr(self._expr.dt.timestamp(time_unit=_time_unit))\n    return self._from_expr(self._expr.dt.timestamp(time_unit=\"ms\") // 1000)\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.var","title":"<code>var(*, correction: float | Scalar | NullType = 1.0, skip_nulls: bool | Scalar = True) -&gt; Scalar</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def var(\n    self,\n    *,\n    correction: float | Scalar | NullType = 1.0,\n    skip_nulls: bool | Scalar = True,\n) -&gt; Scalar:\n    return self._to_scalar(self._expr.var())\n</code></pre>"},{"location":"polars-column/#dataframe_api_compat.polars_standard.Column.year","title":"<code>year() -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/column_object.py</code> <pre><code>def year(self) -&gt; Column:\n    return self._from_expr(self._expr.dt.year())\n</code></pre>"},{"location":"polars-dataframe/","title":"Polars DataFrame","text":"<p>             Bases: <code>DataFrame</code></p> Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>class DataFrame(DataFrameT):\n    def __init__(\n        self,\n        df: pl.LazyFrame | pl.DataFrame,\n        *,\n        api_version: str,\n        is_persisted: bool = False,\n    ) -&gt; None:\n        self._df = df\n        self._api_version = api_version\n        self._is_persisted = is_persisted\n        assert is_persisted ^ isinstance(df, pl.LazyFrame)\n\n    # Validation helper methods\n\n    def _validate_is_persisted(self) -&gt; pl.DataFrame:\n        if not self._is_persisted:\n            msg = \"Method  requires you to call `.persist` first on the parent dataframe.\\n\\nNote: `.persist` forces materialisation in lazy libraries and so should be called as late as possible in your pipeline, and only once per dataframe.\"\n            raise ValueError(\n                msg,\n            )\n        return self.dataframe  # type: ignore[return-value]\n\n    def __repr__(self) -&gt; str:  # pragma: no cover\n        header = f\" Standard DataFrame (api_version={self._api_version}) \"\n        length = len(header)\n        return (\n            \"\u250c\"\n            + \"\u2500\" * length\n            + \"\u2510\\n\"\n            + f\"|{header}|\\n\"\n            + \"| Add `.dataframe` to see native output         |\\n\"\n            + \"\u2514\"\n            + \"\u2500\" * length\n            + \"\u2518\\n\"\n        )\n\n    def _validate_booleanness(self) -&gt; None:\n        if not all(v == pl.Boolean for v in self.dataframe.schema.values()):\n            msg = \"'any' can only be called on DataFrame where all dtypes are 'bool'\"\n            raise TypeError(\n                msg,\n            )\n\n    def _from_dataframe(self, df: pl.LazyFrame | pl.DataFrame) -&gt; DataFrame:\n        return DataFrame(\n            df,\n            api_version=self._api_version,\n            is_persisted=self._is_persisted,\n        )\n\n    # Properties\n    @property\n    def schema(self) -&gt; dict[str, DType]:\n        return {\n            column_name: dataframe_api_compat.polars_standard.map_polars_dtype_to_standard_dtype(\n                dtype,\n            )\n            for column_name, dtype in self.dataframe.schema.items()\n        }\n\n    @property\n    def column_names(self) -&gt; list[str]:\n        return self.dataframe.columns\n\n    @property\n    def dataframe(self) -&gt; pl.LazyFrame | pl.DataFrame:\n        return self._df\n\n    # In the Standard\n\n    def __dataframe_namespace__(self) -&gt; Namespace:\n        return dataframe_api_compat.polars_standard.Namespace(\n            api_version=self._api_version,\n        )\n\n    def iter_columns(self) -&gt; Iterator[Column]:\n        return (self.col(col_name) for col_name in self.column_names)\n\n    def col(self, value: str) -&gt; Column:\n        from dataframe_api_compat.polars_standard.column_object import Column\n\n        if isinstance(self.dataframe, pl.DataFrame):\n            return Column(\n                self.dataframe.get_column(value),\n                df=None,\n                api_version=self._api_version,\n                is_persisted=True,\n            )\n        return Column(\n            pl.col(value),\n            df=self,\n            api_version=self._api_version,\n            is_persisted=False,\n        )\n\n    def shape(self) -&gt; tuple[int, int]:\n        df = self._validate_is_persisted()\n        return df.shape\n\n    def group_by(self, *keys: str) -&gt; GroupBy:\n        from dataframe_api_compat.polars_standard.group_by_object import GroupBy\n\n        return GroupBy(self, list(keys), api_version=self._api_version)\n\n    def select(self, *columns: str) -&gt; DataFrame:\n        cols = list(columns)\n        if cols and not isinstance(cols[0], str):\n            msg = f\"Expected iterable of str, but the first element is: {type(cols[0])}\"\n            raise TypeError(msg)\n        return self._from_dataframe(\n            self._df.select(cols),\n        )\n\n    def take(self, indices: Column) -&gt; DataFrame:\n        _indices = validate_comparand(self, indices)\n        if Version(\"0.19.14\") &gt; POLARS_VERSION:\n            return self._from_dataframe(\n                self.dataframe.select(pl.all().take(_indices)),\n            )\n        return self._from_dataframe(\n            self.dataframe.select(pl.all().gather(_indices)),\n        )\n\n    def slice_rows(\n        self,\n        start: int | None,\n        stop: int | None,\n        step: int | None,\n    ) -&gt; DataFrame:\n        return self._from_dataframe(self._df[start:stop:step])\n\n    def filter(self, mask: Column) -&gt; DataFrame:\n        _mask = validate_comparand(self, mask)\n        return self._from_dataframe(self._df.filter(_mask))\n\n    def assign(self, *columns: Column) -&gt; DataFrame:\n        from dataframe_api_compat.polars_standard.column_object import Column\n\n        new_columns: list[pl.Expr] = []\n        for col in columns:\n            if not isinstance(col, Column):\n                msg = (\n                    f\"Expected iterable of Column, but the first element is: {type(col)}\"\n                )\n                raise TypeError(msg)\n            _expr = validate_comparand(self, col)\n            new_columns.append(_expr)\n        df = self.dataframe.with_columns(new_columns)\n        return self._from_dataframe(df)\n\n    def drop(self, *labels: str) -&gt; DataFrame:\n        return self._from_dataframe(self.dataframe.drop(labels))\n\n    def rename(self, mapping: Mapping[str, str]) -&gt; DataFrame:\n        if not isinstance(mapping, collections.abc.Mapping):\n            msg = f\"Expected Mapping, got: {type(mapping)}\"\n            raise TypeError(msg)\n        return self._from_dataframe(\n            self.dataframe.rename(dict(mapping)),\n        )\n\n    def get_column_names(self) -&gt; list[str]:  # pragma: no cover\n        # DO NOT REMOVE\n        # This one is used in upstream tests - even if deprecated,\n        # just leave it in for backwards compatibility\n        return self.dataframe.columns\n\n    def sort(\n        self,\n        *keys: str,\n        ascending: Sequence[bool] | bool = True,\n        nulls_position: Literal[\"first\", \"last\"] = \"last\",\n    ) -&gt; DataFrame:\n        if not keys:\n            keys = tuple(self.dataframe.columns)\n        # TODO: what if there's multiple `ascending`?\n        return self._from_dataframe(\n            self.dataframe.sort(list(keys), descending=not ascending),\n        )\n\n    # Binary operations\n\n    def __eq__(  # type: ignore[override]\n        self,\n        other: AnyScalar,\n    ) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__eq__(other)),  # type: ignore[operator]\n        )\n\n    def __ne__(  # type: ignore[override]\n        self,\n        other: AnyScalar,\n    ) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__ne__(other)),  # type: ignore[operator]\n        )\n\n    def __ge__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__ge__(other)),  # type: ignore[operator]\n        )\n\n    def __gt__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__gt__(other)),  # type: ignore[operator]\n        )\n\n    def __le__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__le__(other)),  # type: ignore[operator]\n        )\n\n    def __lt__(self, other: AnyScalar) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__lt__(other)),  # type: ignore[operator]\n        )\n\n    def __and__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\") &amp; _other),\n        )\n\n    def __rand__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self.__and__(_other)\n\n    def __or__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.with_columns(\n                (pl.col(col) | _other).alias(col) for col in self.dataframe.columns\n            ),\n        )\n\n    def __ror__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self.__or__(_other)\n\n    def __add__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__add__(_other)),\n        )\n\n    def __radd__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self.__add__(_other)\n\n    def __sub__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__sub__(_other)),\n        )\n\n    def __rsub__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return -1 * self.__sub__(_other)\n\n    def __mul__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__mul__(_other)),\n        )\n\n    def __rmul__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self.__mul__(_other)\n\n    def __truediv__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__truediv__(_other)),\n        )\n\n    def __rtruediv__(self, other: AnyScalar) -&gt; DataFrame:  # pragma: no cover\n        _other = validate_comparand(self, other)\n        raise NotImplementedError\n\n    def __floordiv__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").__floordiv__(_other)),\n        )\n\n    def __rfloordiv__(self, other: AnyScalar) -&gt; DataFrame:  # pragma: no cover\n        _other = validate_comparand(self, other)\n        raise NotImplementedError\n\n    def __pow__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        original_type = self.dataframe.schema\n        ret = self.dataframe.select(\n            [pl.col(col).pow(_other) for col in self.column_names],\n        )\n        for column in self.dataframe.columns:\n            ret = ret.with_columns(pl.col(column).cast(original_type[column]))\n        return self._from_dataframe(ret)\n\n    def __rpow__(self, other: AnyScalar) -&gt; DataFrame:  # pragma: no cover\n        _other = validate_comparand(self, other)\n        raise NotImplementedError\n\n    def __mod__(self, other: AnyScalar) -&gt; DataFrame:\n        _other = validate_comparand(self, other)\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\") % _other),\n        )\n\n    def __rmod__(self, other: AnyScalar) -&gt; DataFrame:  # type: ignore[misc]  # pragma: no cover\n        _other = validate_comparand(self, other)\n        raise NotImplementedError\n\n    def __divmod__(\n        self,\n        other: DataFrame | AnyScalar,\n    ) -&gt; tuple[DataFrame, DataFrame]:\n        _other = validate_comparand(self, other)\n        quotient_df = self.dataframe.with_columns(pl.col(\"*\") // _other)\n        remainder_df = self.dataframe.with_columns(\n            pl.col(\"*\") - (pl.col(\"*\") // _other) * _other,\n        )\n        return self._from_dataframe(\n            quotient_df,\n        ), self._from_dataframe(remainder_df)\n\n    # Unary\n\n    def __invert__(self) -&gt; DataFrame:\n        self._validate_booleanness()\n        return self._from_dataframe(\n            self.dataframe.select(~pl.col(\"*\")),\n        )\n\n    def __iter__(self) -&gt; NoReturn:\n        raise NotImplementedError\n\n    # Reductions\n\n    def any(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").any()),\n        )\n\n    def all(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").all()),\n        )\n\n    def min(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").min()),\n        )\n\n    def max(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").max()),\n        )\n\n    def sum(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").sum()),\n        )\n\n    def prod(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").product()),\n        )\n\n    def mean(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").mean()),\n        )\n\n    def median(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").median()),\n        )\n\n    def std(\n        self,\n        *,\n        correction: float | Scalar | NullType = 1.0,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").std()),\n        )\n\n    def var(\n        self,\n        *,\n        correction: float | Scalar | NullType = 1.0,\n        skip_nulls: bool | Scalar = True,\n    ) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.select(pl.col(\"*\").var()),\n        )\n\n    # Transformations\n\n    def is_null(self) -&gt; DataFrame:\n        return self._from_dataframe(\n            self.dataframe.with_columns(pl.col(\"*\").is_null()),\n        )\n\n    def is_nan(self) -&gt; DataFrame:\n        df = self.dataframe.with_columns(pl.col(\"*\").is_nan())\n        return self._from_dataframe(df)\n\n    def fill_nan(\n        self,\n        value: float | NullType | Scalar,\n    ) -&gt; DataFrame:\n        _value = validate_comparand(self, value)\n        if isinstance(_value, self.__dataframe_namespace__().NullType):\n            return self._from_dataframe(\n                self.dataframe.fill_nan(pl.lit(None)),\n            )\n        return self._from_dataframe(\n            self.dataframe.fill_nan(_value),\n        )\n\n    def fill_null(\n        self,\n        value: AnyScalar,\n        *,\n        column_names: list[str] | None = None,\n    ) -&gt; DataFrame:\n        if column_names is None:\n            column_names = self.dataframe.columns\n        df = self.dataframe.with_columns(\n            pl.col(col).fill_null(value) for col in column_names\n        )\n        return self._from_dataframe(df)\n\n    def drop_nulls(\n        self,\n        *,\n        column_names: list[str] | None = None,\n    ) -&gt; DataFrame:\n        namespace = self.__dataframe_namespace__()\n        mask = ~namespace.any_horizontal(\n            *[\n                self.col(col_name).is_null()\n                for col_name in column_names or self.column_names\n            ],\n        )\n        return self.filter(mask)\n\n    # Other\n\n    def join(\n        self,\n        other: DataFrame,\n        *,\n        how: Literal[\"left\", \"inner\", \"outer\"],\n        left_on: str | list[str],\n        right_on: str | list[str],\n    ) -&gt; DataFrame:\n        if how not in [\"left\", \"inner\", \"outer\"]:\n            msg = f\"Expected 'left', 'inner', 'outer', got: {how}\"\n            raise ValueError(msg)\n\n        if isinstance(left_on, str):\n            left_on = [left_on]\n        if isinstance(right_on, str):\n            right_on = [right_on]\n\n        if overlap := (set(self.column_names) - set(left_on)).intersection(\n            set(other.column_names) - set(right_on),\n        ):\n            msg = f\"Found overlapping columns in join: {overlap}. Please rename columns to avoid this.\"\n            raise ValueError(msg)\n\n        # workaround for https://github.com/pola-rs/polars/issues/9335\n        extra_right_keys = set(right_on).difference(left_on)\n        other_df = other.dataframe\n        token = generate_random_token(self.column_names + other.column_names)\n        other_df = other_df.with_columns(\n            [pl.col(i).alias(f\"{i}_{token}\") for i in extra_right_keys],\n        )\n\n        result = self.dataframe.join(\n            other_df,  # type: ignore[arg-type]\n            left_on=left_on,\n            right_on=right_on,\n            how=how,\n        )\n        result = result.rename({f\"{i}_{token}\": i for i in extra_right_keys})\n\n        return self._from_dataframe(result)\n\n    def persist(self) -&gt; DataFrame:\n        if isinstance(self.dataframe, pl.DataFrame):\n            warnings.warn(\n                \"Calling `.persist` on DataFrame that was already persisted\",\n                UserWarning,\n                stacklevel=2,\n            )\n            df = self.dataframe\n        else:\n            df = self.dataframe.collect()\n        return DataFrame(\n            df,\n            api_version=self._api_version,\n            is_persisted=True,\n        )\n\n    # Conversion\n\n    def to_array(self, dtype: DType | None = None) -&gt; Any:\n        df = self._validate_is_persisted()\n        return df.to_numpy()\n\n    def cast(self, dtypes: Mapping[str, DType]) -&gt; DataFrame:\n        from dataframe_api_compat.polars_standard import _map_standard_to_polars_dtypes\n\n        df = self._df\n        return self._from_dataframe(\n            df.with_columns(\n                [\n                    pl.col(col).cast(_map_standard_to_polars_dtypes(dtype))\n                    for col, dtype in dtypes.items()\n                ],\n            ),\n        )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.column_names","title":"<code>column_names: list[str]</code>  <code>property</code>","text":""},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.dataframe","title":"<code>dataframe: pl.LazyFrame | pl.DataFrame</code>  <code>property</code>","text":""},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.schema","title":"<code>schema: dict[str, DType]</code>  <code>property</code>","text":""},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__add__","title":"<code>__add__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __add__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__add__(_other)),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__and__","title":"<code>__and__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __and__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\") &amp; _other),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__dataframe_namespace__","title":"<code>__dataframe_namespace__() -&gt; Namespace</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __dataframe_namespace__(self) -&gt; Namespace:\n    return dataframe_api_compat.polars_standard.Namespace(\n        api_version=self._api_version,\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__divmod__","title":"<code>__divmod__(other: DataFrame | AnyScalar) -&gt; tuple[DataFrame, DataFrame]</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __divmod__(\n    self,\n    other: DataFrame | AnyScalar,\n) -&gt; tuple[DataFrame, DataFrame]:\n    _other = validate_comparand(self, other)\n    quotient_df = self.dataframe.with_columns(pl.col(\"*\") // _other)\n    remainder_df = self.dataframe.with_columns(\n        pl.col(\"*\") - (pl.col(\"*\") // _other) * _other,\n    )\n    return self._from_dataframe(\n        quotient_df,\n    ), self._from_dataframe(remainder_df)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__eq__","title":"<code>__eq__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __eq__(  # type: ignore[override]\n    self,\n    other: AnyScalar,\n) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__eq__(other)),  # type: ignore[operator]\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__floordiv__","title":"<code>__floordiv__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __floordiv__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__floordiv__(_other)),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__ge__","title":"<code>__ge__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __ge__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__ge__(other)),  # type: ignore[operator]\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__gt__","title":"<code>__gt__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __gt__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__gt__(other)),  # type: ignore[operator]\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__init__","title":"<code>__init__(df: pl.LazyFrame | pl.DataFrame, *, api_version: str, is_persisted: bool = False) -&gt; None</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __init__(\n    self,\n    df: pl.LazyFrame | pl.DataFrame,\n    *,\n    api_version: str,\n    is_persisted: bool = False,\n) -&gt; None:\n    self._df = df\n    self._api_version = api_version\n    self._is_persisted = is_persisted\n    assert is_persisted ^ isinstance(df, pl.LazyFrame)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__invert__","title":"<code>__invert__() -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __invert__(self) -&gt; DataFrame:\n    self._validate_booleanness()\n    return self._from_dataframe(\n        self.dataframe.select(~pl.col(\"*\")),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__iter__","title":"<code>__iter__() -&gt; NoReturn</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __iter__(self) -&gt; NoReturn:\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__le__","title":"<code>__le__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __le__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__le__(other)),  # type: ignore[operator]\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__lt__","title":"<code>__lt__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __lt__(self, other: AnyScalar) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__lt__(other)),  # type: ignore[operator]\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__mod__","title":"<code>__mod__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __mod__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\") % _other),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__mul__","title":"<code>__mul__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __mul__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__mul__(_other)),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__ne__","title":"<code>__ne__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __ne__(  # type: ignore[override]\n    self,\n    other: AnyScalar,\n) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__ne__(other)),  # type: ignore[operator]\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__or__","title":"<code>__or__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __or__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.with_columns(\n            (pl.col(col) | _other).alias(col) for col in self.dataframe.columns\n        ),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__pow__","title":"<code>__pow__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __pow__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    original_type = self.dataframe.schema\n    ret = self.dataframe.select(\n        [pl.col(col).pow(_other) for col in self.column_names],\n    )\n    for column in self.dataframe.columns:\n        ret = ret.with_columns(pl.col(column).cast(original_type[column]))\n    return self._from_dataframe(ret)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__radd__","title":"<code>__radd__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __radd__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self.__add__(_other)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__rand__","title":"<code>__rand__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __rand__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self.__and__(_other)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__repr__","title":"<code>__repr__() -&gt; str</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __repr__(self) -&gt; str:  # pragma: no cover\n    header = f\" Standard DataFrame (api_version={self._api_version}) \"\n    length = len(header)\n    return (\n        \"\u250c\"\n        + \"\u2500\" * length\n        + \"\u2510\\n\"\n        + f\"|{header}|\\n\"\n        + \"| Add `.dataframe` to see native output         |\\n\"\n        + \"\u2514\"\n        + \"\u2500\" * length\n        + \"\u2518\\n\"\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__rfloordiv__","title":"<code>__rfloordiv__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __rfloordiv__(self, other: AnyScalar) -&gt; DataFrame:  # pragma: no cover\n    _other = validate_comparand(self, other)\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__rmod__","title":"<code>__rmod__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __rmod__(self, other: AnyScalar) -&gt; DataFrame:  # type: ignore[misc]  # pragma: no cover\n    _other = validate_comparand(self, other)\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__rmul__","title":"<code>__rmul__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __rmul__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self.__mul__(_other)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__ror__","title":"<code>__ror__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __ror__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self.__or__(_other)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__rpow__","title":"<code>__rpow__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __rpow__(self, other: AnyScalar) -&gt; DataFrame:  # pragma: no cover\n    _other = validate_comparand(self, other)\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__rsub__","title":"<code>__rsub__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __rsub__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return -1 * self.__sub__(_other)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__rtruediv__","title":"<code>__rtruediv__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __rtruediv__(self, other: AnyScalar) -&gt; DataFrame:  # pragma: no cover\n    _other = validate_comparand(self, other)\n    raise NotImplementedError\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__sub__","title":"<code>__sub__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __sub__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__sub__(_other)),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.__truediv__","title":"<code>__truediv__(other: AnyScalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def __truediv__(self, other: AnyScalar) -&gt; DataFrame:\n    _other = validate_comparand(self, other)\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").__truediv__(_other)),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.all","title":"<code>all(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def all(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").all()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.any","title":"<code>any(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def any(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").any()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.assign","title":"<code>assign(*columns: Column) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def assign(self, *columns: Column) -&gt; DataFrame:\n    from dataframe_api_compat.polars_standard.column_object import Column\n\n    new_columns: list[pl.Expr] = []\n    for col in columns:\n        if not isinstance(col, Column):\n            msg = (\n                f\"Expected iterable of Column, but the first element is: {type(col)}\"\n            )\n            raise TypeError(msg)\n        _expr = validate_comparand(self, col)\n        new_columns.append(_expr)\n    df = self.dataframe.with_columns(new_columns)\n    return self._from_dataframe(df)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.col","title":"<code>col(value: str) -&gt; Column</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def col(self, value: str) -&gt; Column:\n    from dataframe_api_compat.polars_standard.column_object import Column\n\n    if isinstance(self.dataframe, pl.DataFrame):\n        return Column(\n            self.dataframe.get_column(value),\n            df=None,\n            api_version=self._api_version,\n            is_persisted=True,\n        )\n    return Column(\n        pl.col(value),\n        df=self,\n        api_version=self._api_version,\n        is_persisted=False,\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.drop","title":"<code>drop(*labels: str) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def drop(self, *labels: str) -&gt; DataFrame:\n    return self._from_dataframe(self.dataframe.drop(labels))\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.drop_nulls","title":"<code>drop_nulls(*, column_names: list[str] | None = None) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def drop_nulls(\n    self,\n    *,\n    column_names: list[str] | None = None,\n) -&gt; DataFrame:\n    namespace = self.__dataframe_namespace__()\n    mask = ~namespace.any_horizontal(\n        *[\n            self.col(col_name).is_null()\n            for col_name in column_names or self.column_names\n        ],\n    )\n    return self.filter(mask)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.fill_nan","title":"<code>fill_nan(value: float | NullType | Scalar) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def fill_nan(\n    self,\n    value: float | NullType | Scalar,\n) -&gt; DataFrame:\n    _value = validate_comparand(self, value)\n    if isinstance(_value, self.__dataframe_namespace__().NullType):\n        return self._from_dataframe(\n            self.dataframe.fill_nan(pl.lit(None)),\n        )\n    return self._from_dataframe(\n        self.dataframe.fill_nan(_value),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.fill_null","title":"<code>fill_null(value: AnyScalar, *, column_names: list[str] | None = None) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def fill_null(\n    self,\n    value: AnyScalar,\n    *,\n    column_names: list[str] | None = None,\n) -&gt; DataFrame:\n    if column_names is None:\n        column_names = self.dataframe.columns\n    df = self.dataframe.with_columns(\n        pl.col(col).fill_null(value) for col in column_names\n    )\n    return self._from_dataframe(df)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.filter","title":"<code>filter(mask: Column) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def filter(self, mask: Column) -&gt; DataFrame:\n    _mask = validate_comparand(self, mask)\n    return self._from_dataframe(self._df.filter(_mask))\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.get_column_names","title":"<code>get_column_names() -&gt; list[str]</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def get_column_names(self) -&gt; list[str]:  # pragma: no cover\n    # DO NOT REMOVE\n    # This one is used in upstream tests - even if deprecated,\n    # just leave it in for backwards compatibility\n    return self.dataframe.columns\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.take","title":"<code>take(indices: Column) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def take(self, indices: Column) -&gt; DataFrame:\n    _indices = validate_comparand(self, indices)\n    if Version(\"0.19.14\") &gt; POLARS_VERSION:\n        return self._from_dataframe(\n            self.dataframe.select(pl.all().take(_indices)),\n        )\n    return self._from_dataframe(\n        self.dataframe.select(pl.all().gather(_indices)),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.group_by","title":"<code>group_by(*keys: str) -&gt; GroupBy</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def group_by(self, *keys: str) -&gt; GroupBy:\n    from dataframe_api_compat.polars_standard.group_by_object import GroupBy\n\n    return GroupBy(self, list(keys), api_version=self._api_version)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.is_nan","title":"<code>is_nan() -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def is_nan(self) -&gt; DataFrame:\n    df = self.dataframe.with_columns(pl.col(\"*\").is_nan())\n    return self._from_dataframe(df)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.is_null","title":"<code>is_null() -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def is_null(self) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.with_columns(pl.col(\"*\").is_null()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.join","title":"<code>join(other: DataFrame, *, how: Literal['left', 'inner', 'outer'], left_on: str | list[str], right_on: str | list[str]) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def join(\n    self,\n    other: DataFrame,\n    *,\n    how: Literal[\"left\", \"inner\", \"outer\"],\n    left_on: str | list[str],\n    right_on: str | list[str],\n) -&gt; DataFrame:\n    if how not in [\"left\", \"inner\", \"outer\"]:\n        msg = f\"Expected 'left', 'inner', 'outer', got: {how}\"\n        raise ValueError(msg)\n\n    if isinstance(left_on, str):\n        left_on = [left_on]\n    if isinstance(right_on, str):\n        right_on = [right_on]\n\n    if overlap := (set(self.column_names) - set(left_on)).intersection(\n        set(other.column_names) - set(right_on),\n    ):\n        msg = f\"Found overlapping columns in join: {overlap}. Please rename columns to avoid this.\"\n        raise ValueError(msg)\n\n    # workaround for https://github.com/pola-rs/polars/issues/9335\n    extra_right_keys = set(right_on).difference(left_on)\n    other_df = other.dataframe\n    token = generate_random_token(self.column_names + other.column_names)\n    other_df = other_df.with_columns(\n        [pl.col(i).alias(f\"{i}_{token}\") for i in extra_right_keys],\n    )\n\n    result = self.dataframe.join(\n        other_df,  # type: ignore[arg-type]\n        left_on=left_on,\n        right_on=right_on,\n        how=how,\n    )\n    result = result.rename({f\"{i}_{token}\": i for i in extra_right_keys})\n\n    return self._from_dataframe(result)\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.max","title":"<code>max(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def max(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").max()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.mean","title":"<code>mean(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def mean(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").mean()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.median","title":"<code>median(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def median(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").median()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.min","title":"<code>min(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def min(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").min()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.persist","title":"<code>persist() -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def persist(self) -&gt; DataFrame:\n    if isinstance(self.dataframe, pl.DataFrame):\n        warnings.warn(\n            \"Calling `.persist` on DataFrame that was already persisted\",\n            UserWarning,\n            stacklevel=2,\n        )\n        df = self.dataframe\n    else:\n        df = self.dataframe.collect()\n    return DataFrame(\n        df,\n        api_version=self._api_version,\n        is_persisted=True,\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.prod","title":"<code>prod(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def prod(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").product()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.rename","title":"<code>rename(mapping: Mapping[str, str]) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def rename(self, mapping: Mapping[str, str]) -&gt; DataFrame:\n    if not isinstance(mapping, collections.abc.Mapping):\n        msg = f\"Expected Mapping, got: {type(mapping)}\"\n        raise TypeError(msg)\n    return self._from_dataframe(\n        self.dataframe.rename(dict(mapping)),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.select","title":"<code>select(*columns: str) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def select(self, *columns: str) -&gt; DataFrame:\n    cols = list(columns)\n    if cols and not isinstance(cols[0], str):\n        msg = f\"Expected iterable of str, but the first element is: {type(cols[0])}\"\n        raise TypeError(msg)\n    return self._from_dataframe(\n        self._df.select(cols),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.shape","title":"<code>shape() -&gt; tuple[int, int]</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def shape(self) -&gt; tuple[int, int]:\n    df = self._validate_is_persisted()\n    return df.shape\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.slice_rows","title":"<code>slice_rows(start: int | None, stop: int | None, step: int | None) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def slice_rows(\n    self,\n    start: int | None,\n    stop: int | None,\n    step: int | None,\n) -&gt; DataFrame:\n    return self._from_dataframe(self._df[start:stop:step])\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.sort","title":"<code>sort(*keys: str, ascending: Sequence[bool] | bool = True, nulls_position: Literal['first', 'last'] = 'last') -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def sort(\n    self,\n    *keys: str,\n    ascending: Sequence[bool] | bool = True,\n    nulls_position: Literal[\"first\", \"last\"] = \"last\",\n) -&gt; DataFrame:\n    if not keys:\n        keys = tuple(self.dataframe.columns)\n    # TODO: what if there's multiple `ascending`?\n    return self._from_dataframe(\n        self.dataframe.sort(list(keys), descending=not ascending),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.std","title":"<code>std(*, correction: float | Scalar | NullType = 1.0, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def std(\n    self,\n    *,\n    correction: float | Scalar | NullType = 1.0,\n    skip_nulls: bool | Scalar = True,\n) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").std()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.sum","title":"<code>sum(*, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def sum(self, *, skip_nulls: bool | Scalar = True) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").sum()),\n    )\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.to_array","title":"<code>to_array(dtype: DType | None = None) -&gt; Any</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def to_array(self, dtype: DType | None = None) -&gt; Any:\n    df = self._validate_is_persisted()\n    return df.to_numpy()\n</code></pre>"},{"location":"polars-dataframe/#dataframe_api_compat.polars_standard.DataFrame.var","title":"<code>var(*, correction: float | Scalar | NullType = 1.0, skip_nulls: bool | Scalar = True) -&gt; DataFrame</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/dataframe_object.py</code> <pre><code>def var(\n    self,\n    *,\n    correction: float | Scalar | NullType = 1.0,\n    skip_nulls: bool | Scalar = True,\n) -&gt; DataFrame:\n    return self._from_dataframe(\n        self.dataframe.select(pl.col(\"*\").var()),\n    )\n</code></pre>"},{"location":"polars-namespace/","title":"Pandas Namespace","text":"<p>             Bases: <code>Namespace</code></p> Source code in <code>dataframe_api_compat/pandas_standard/__init__.py</code> <pre><code>class Namespace(NamespaceT):\n    def __init__(self, *, api_version: str) -&gt; None:\n        self.__dataframe_api_version__ = api_version\n        self._api_version = api_version\n\n    class Int64(Int64T):\n        ...\n\n    class Int32(Int32T):\n        ...\n\n    class Int16(Int16T):\n        ...\n\n    class Int8(Int8T):\n        ...\n\n    class UInt64(UInt64T):\n        ...\n\n    class UInt32(UInt32T):\n        ...\n\n    class UInt16(UInt16T):\n        ...\n\n    class UInt8(UInt8T):\n        ...\n\n    class Float64(Float64T):\n        ...\n\n    class Float32(Float32T):\n        ...\n\n    class Bool(BoolT):\n        ...\n\n    class String(StringT):\n        ...\n\n    class Date(DateT):\n        ...\n\n    class Datetime(DatetimeT):\n        def __init__(\n            self,\n            time_unit: Literal[\"ms\", \"us\"],\n            time_zone: str | None = None,\n        ) -&gt; None:\n            self.time_unit = time_unit\n            # TODO validate time zone\n            self.time_zone = time_zone\n\n    class Duration(DurationT):\n        def __init__(self, time_unit: Literal[\"ms\", \"us\"]) -&gt; None:\n            self.time_unit = time_unit\n\n    class NullType(NullTypeT):\n        ...\n\n    null = NullType()\n\n    def dataframe_from_columns(\n        self,\n        *columns: ColumnT,\n    ) -&gt; DataFrame:\n        data = {}\n        api_versions: set[str] = set()\n        for col in columns:\n            ser = col._materialise()  # type: ignore[attr-defined]\n            data[ser.name] = ser\n            api_versions.add(col._api_version)  # type: ignore[attr-defined]\n        return DataFrame(pd.DataFrame(data), api_version=list(api_versions)[0])\n\n    def column_from_1d_array(  # type: ignore[override]\n        self,\n        data: Any,\n        *,\n        name: str | None = None,\n    ) -&gt; Column:\n        ser = pd.Series(data, name=name)\n        return Column(ser, api_version=self._api_version, df=None, is_persisted=True)\n\n    def column_from_sequence(\n        self,\n        sequence: Sequence[Any],\n        *,\n        dtype: DType | None = None,\n        name: str = \"\",\n    ) -&gt; Column:\n        if dtype is not None:\n            ser = pd.Series(\n                sequence,\n                dtype=map_standard_dtype_to_pandas_dtype(dtype),\n                name=name,\n            )\n        else:\n            ser = pd.Series(sequence, name=name)\n        return Column(ser, api_version=self._api_version, df=None, is_persisted=True)\n\n    def concat(\n        self,\n        dataframes: Sequence[DataFrameT],\n    ) -&gt; DataFrame:\n        dataframes = cast(\"Sequence[DataFrame]\", dataframes)\n        dtypes = dataframes[0].dataframe.dtypes\n        dfs: list[pd.DataFrame] = []\n        api_versions: set[str] = set()\n        for df in dataframes:\n            try:\n                pd.testing.assert_series_equal(\n                    df.dataframe.dtypes,\n                    dtypes,\n                )\n            except AssertionError as exc:\n                msg = \"Expected matching columns\"\n                raise ValueError(msg) from exc\n            dfs.append(df.dataframe)\n            api_versions.add(df._api_version)\n        if len(api_versions) &gt; 1:  # pragma: no cover\n            msg = f\"Multiple api versions found: {api_versions}\"\n            raise ValueError(msg)\n        return DataFrame(\n            pd.concat(\n                dfs,\n                axis=0,\n                ignore_index=True,\n            ),\n            api_version=api_versions.pop(),\n        )\n\n    def dataframe_from_2d_array(\n        self,\n        data: Any,\n        *,\n        names: Sequence[str],\n    ) -&gt; DataFrame:\n        df = pd.DataFrame(data, columns=list(names))\n        return DataFrame(df, api_version=self._api_version)\n\n    def is_null(self, value: Any) -&gt; bool:\n        return value is self.null\n\n    def is_dtype(self, dtype: DType, kind: str | tuple[str, ...]) -&gt; bool:\n        if isinstance(kind, str):\n            kind = (kind,)\n        dtypes: set[Any] = set()\n        for _kind in kind:\n            if _kind == \"bool\":\n                dtypes.add(Namespace.Bool)\n            if _kind == \"signed integer\" or _kind == \"integral\" or _kind == \"numeric\":\n                dtypes |= {\n                    Namespace.Int64,\n                    Namespace.Int32,\n                    Namespace.Int16,\n                    Namespace.Int8,\n                }\n            if _kind == \"unsigned integer\" or _kind == \"integral\" or _kind == \"numeric\":\n                dtypes |= {\n                    Namespace.UInt64,\n                    Namespace.UInt32,\n                    Namespace.UInt16,\n                    Namespace.UInt8,\n                }\n            if _kind == \"floating\" or _kind == \"numeric\":\n                dtypes |= {Namespace.Float64, Namespace.Float32}\n            if _kind == \"string\":\n                dtypes.add(Namespace.String)\n        return isinstance(dtype, tuple(dtypes))\n\n    def date(self, year: int, month: int, day: int) -&gt; Scalar:\n        return Scalar(\n            pd.Timestamp(dt.date(year, month, day)),\n            api_version=self._api_version,\n            df=None,\n            is_persisted=True,\n        )\n\n    # --- horizontal reductions\n\n    def all_horizontal(self, *columns: ColumnT, skip_nulls: bool = True) -&gt; ColumnT:\n        return reduce(lambda x, y: x &amp; y, columns)\n\n    def any_horizontal(self, *columns: ColumnT, skip_nulls: bool = True) -&gt; ColumnT:\n        return reduce(lambda x, y: x | y, columns)\n\n    def sorted_indices(\n        self,\n        *columns: ColumnT,\n        ascending: Sequence[bool] | bool = True,\n        nulls_position: Literal[\"first\", \"last\"] = \"last\",\n    ) -&gt; Column:\n        raise NotImplementedError\n\n    def unique_indices(\n        self,\n        *columns: ColumnT,\n        skip_nulls: bool | ScalarT = True,\n    ) -&gt; Column:\n        raise NotImplementedError\n\n    class Aggregation(AggregationT):\n        def __init__(self, column_name: str, output_name: str, aggregation: str) -&gt; None:\n            self.column_name = column_name\n            self.output_name = output_name\n            self.aggregation = aggregation\n\n        def __repr__(self) -&gt; str:  # pragma: no cover\n            return f\"{self.__class__.__name__}({self.column_name!r}, {self.output_name!r}, {self.aggregation!r})\"\n\n        def _replace(self, **kwargs: str) -&gt; AggregationT:\n            return self.__class__(\n                column_name=kwargs.get(\"column_name\", self.column_name),\n                output_name=kwargs.get(\"output_name\", self.output_name),\n                aggregation=kwargs.get(\"aggregation\", self.aggregation),\n            )\n\n        def rename(self, name: str | ScalarT) -&gt; AggregationT:\n            return self.__class__(self.column_name, name, self.aggregation)  # type: ignore[arg-type]\n\n        @classmethod\n        def any(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"any\")\n\n        @classmethod\n        def all(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"all\")\n\n        @classmethod\n        def min(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"min\")\n\n        @classmethod\n        def max(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"max\")\n\n        @classmethod\n        def sum(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"sum\")\n\n        @classmethod\n        def prod(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"prod\")\n\n        @classmethod\n        def median(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"median\")\n\n        @classmethod\n        def mean(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"mean\")\n\n        @classmethod\n        def std(\n            cls: AggregationT,\n            column: str,\n            *,\n            correction: float | ScalarT | NullTypeT = 1,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"std\")\n\n        @classmethod\n        def var(\n            cls: AggregationT,\n            column: str,\n            *,\n            correction: float | ScalarT | NullTypeT = 1,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"var\")\n\n        @classmethod\n        def size(\n            cls: AggregationT,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(\"__placeholder__\", \"size\", \"size\")\n</code></pre>"},{"location":"polars-namespace/#dataframe_api_compat.pandas_standard.Namespace.__init__","title":"<code>__init__(*, api_version: str) -&gt; None</code>","text":"Source code in <code>dataframe_api_compat/pandas_standard/__init__.py</code> <pre><code>def __init__(self, *, api_version: str) -&gt; None:\n    self.__dataframe_api_version__ = api_version\n    self._api_version = api_version\n</code></pre>"},{"location":"polars-scalar/","title":"Polars Namespace","text":"<p>             Bases: <code>Namespace</code></p> Source code in <code>dataframe_api_compat/polars_standard/__init__.py</code> <pre><code>class Namespace(NamespaceT):\n    def __init__(self, *, api_version: str) -&gt; None:\n        self.__dataframe_api_version__ = api_version\n        self.api_version = api_version\n\n    class Int64(Int64T):\n        ...\n\n    class Int32(Int32T):\n        ...\n\n    class Int16(Int16T):\n        ...\n\n    class Int8(Int8T):\n        ...\n\n    class UInt64(UInt64T):\n        ...\n\n    class UInt32(UInt32T):\n        ...\n\n    class UInt16(UInt16T):\n        ...\n\n    class UInt8(UInt8T):\n        ...\n\n    class Float64(Float64T):\n        ...\n\n    class Float32(Float32T):\n        ...\n\n    class Bool(BoolT):\n        ...\n\n    class String(StringT):\n        ...\n\n    class Date(DateT):\n        ...\n\n    class Datetime(DatetimeT):\n        def __init__(\n            self,\n            time_unit: Literal[\"ms\", \"us\"],\n            time_zone: str | None = None,\n        ) -&gt; None:\n            self.time_unit = time_unit\n            self.time_zone = time_zone\n\n    class Duration(DurationT):\n        def __init__(self, time_unit: Literal[\"ms\", \"us\"]) -&gt; None:\n            self.time_unit = time_unit\n\n    class NullType(NullTypeT):\n        ...\n\n    null = NullType()\n\n    def is_null(self, value: Any) -&gt; bool:\n        return value is self.null\n\n    def dataframe_from_columns(\n        self,\n        *columns: Column,  # type: ignore[override]\n    ) -&gt; DataFrame:\n        data = {}\n        api_version: set[str] = set()\n        for col in columns:\n            ser = col._materialise()\n            data[ser.name] = ser\n            api_version.add(col._api_version)\n        if len(api_version) &gt; 1:  # pragma: no cover\n            msg = f\"found multiple api versions: {api_version}\"\n            raise ValueError(msg)\n        return DataFrame(\n            pl.DataFrame(data).lazy(),\n            api_version=list(api_version)[0],\n        )\n\n    def column_from_1d_array(  # type: ignore[override]\n        self,\n        array: Any,\n        *,\n        name: str = \"\",\n    ) -&gt; Column:\n        ser = pl.Series(values=array, name=name)\n        return Column(ser, api_version=self.api_version, df=None, is_persisted=True)\n\n    def column_from_sequence(\n        self,\n        sequence: Sequence[Any],\n        *,\n        dtype: DType | None = None,\n        name: str = \"\",\n    ) -&gt; Column:\n        if dtype is not None:\n            ser = pl.Series(\n                values=sequence,\n                dtype=_map_standard_to_polars_dtypes(dtype),\n                name=name,\n            )\n        else:\n            ser = pl.Series(values=sequence, name=name)\n        return Column(ser, api_version=self.api_version, df=None, is_persisted=True)\n\n    def dataframe_from_2d_array(\n        self,\n        data: Any,\n        *,\n        names: Sequence[str],\n    ) -&gt; DataFrame:\n        df = pl.DataFrame(\n            data,\n            schema=names,\n        ).lazy()\n        return DataFrame(df, api_version=self.api_version)\n\n    def date(self, year: int, month: int, day: int) -&gt; Scalar:\n        return Scalar(\n            pl.date(year, month, day),\n            api_version=self.api_version,\n            df=None,\n            is_persisted=True,\n        )\n\n    class Aggregation(AggregationT):\n        def __init__(self, column_name: str, output_name: str, aggregation: str) -&gt; None:\n            self.column_name = column_name\n            self.output_name = output_name\n            self.aggregation = aggregation\n\n        def rename(self, name: str | ScalarT) -&gt; AggregationT:\n            return self.__class__(self.column_name, name, self.aggregation)  # type: ignore[arg-type]\n\n        @classmethod\n        def any(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"any\")\n\n        @classmethod\n        def all(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"all\")\n\n        @classmethod\n        def min(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"min\")\n\n        @classmethod\n        def max(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"max\")\n\n        @classmethod\n        def sum(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"sum\")\n\n        @classmethod\n        def prod(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"product\")\n\n        @classmethod\n        def median(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"median\")\n\n        @classmethod\n        def mean(\n            cls: AggregationT,\n            column: str,\n            *,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"mean\")\n\n        @classmethod\n        def std(\n            cls: AggregationT,\n            column: str,\n            *,\n            correction: float | ScalarT | NullTypeT = 1,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"std\")\n\n        @classmethod\n        def var(\n            cls: AggregationT,\n            column: str,\n            *,\n            correction: float | ScalarT | NullTypeT = 1,\n            skip_nulls: bool | ScalarT = True,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(column, column, \"var\")\n\n        @classmethod\n        def size(\n            cls: AggregationT,\n        ) -&gt; AggregationT:\n            return Namespace.Aggregation(\"__placeholder__\", \"size\", \"count\")\n\n    def concat(\n        self,\n        dataframes: Sequence[DataFrameT],\n    ) -&gt; DataFrame:\n        dataframes = cast(\"Sequence[DataFrame]\", dataframes)\n        dfs: list[pl.LazyFrame | pl.DataFrame] = []\n        api_versions: set[str] = set()\n        for df in dataframes:\n            dfs.append(df.dataframe)\n            api_versions.add(df._api_version)\n        if len(api_versions) &gt; 1:  # pragma: no cover\n            msg = f\"Multiple api versions found: {api_versions}\"\n            raise ValueError(msg)\n        # todo raise if not all share persistedness\n        return DataFrame(\n            pl.concat(dfs),  # type: ignore[type-var]\n            api_version=api_versions.pop(),\n        )\n\n    def is_dtype(self, dtype: Any, kind: str | tuple[str, ...]) -&gt; bool:\n        if isinstance(kind, str):\n            kind = (kind,)\n        dtypes: set[Any] = set()\n        for _kind in kind:\n            if _kind == \"bool\":\n                dtypes.add(self.Bool)\n            if _kind == \"signed integer\" or _kind == \"integral\" or _kind == \"numeric\":\n                dtypes |= {self.Int64, self.Int32, self.Int16, self.Int8}\n            if _kind == \"unsigned integer\" or _kind == \"integral\" or _kind == \"numeric\":\n                dtypes |= {self.UInt64, self.UInt32, self.UInt16, self.UInt8}\n            if _kind == \"floating\" or _kind == \"numeric\":\n                dtypes |= {self.Float64, self.Float32}\n            if _kind == \"string\":\n                dtypes.add(self.String)\n        return isinstance(dtype, tuple(dtypes))\n\n    # Horizontal reductions\n\n    def all_horizontal(self, *columns: ColumnT, skip_nulls: bool = True) -&gt; ColumnT:\n        return reduce(lambda x, y: x &amp; y, columns)\n\n    def any_horizontal(self, *columns: ColumnT, skip_nulls: bool = True) -&gt; ColumnT:\n        return reduce(lambda x, y: x | y, columns)\n\n    def sorted_indices(\n        self,\n        *columns: ColumnT,\n        ascending: Sequence[bool] | bool = True,\n        nulls_position: Literal[\"first\", \"last\"] = \"last\",\n    ) -&gt; Column:\n        raise NotImplementedError\n\n    def unique_indices(self, *columns: ColumnT, skip_nulls: bool = True) -&gt; Column:\n        raise NotImplementedError\n</code></pre>"},{"location":"polars-scalar/#dataframe_api_compat.polars_standard.Namespace.__init__","title":"<code>__init__(*, api_version: str) -&gt; None</code>","text":"Source code in <code>dataframe_api_compat/polars_standard/__init__.py</code> <pre><code>def __init__(self, *, api_version: str) -&gt; None:\n    self.__dataframe_api_version__ = api_version\n    self.api_version = api_version\n</code></pre>"},{"location":"quick_start/","title":"Quick start","text":""},{"location":"quick_start/#prerequisites","title":"Prerequisites","text":"<p>Please start by following the installation instructions</p> <p>Then, please install the following:</p> <ul> <li>pandas</li> <li>Polars</li> </ul>"},{"location":"quick_start/#simple-example","title":"Simple example","text":"<p>Create a Python file <code>t.py</code> with the following content:</p> <pre><code>import pandas as pd\nimport polars as pl\n\n\ndef my_function(df_any):\n    df = df_any.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    column_names = df.column_names\n    return column_names\n\n\ndf_pandas = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\ndf_polars = pl.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n\nprint('pandas result: ', my_function(df_pandas))\nprint('Polars result: ', my_function(df_polars))\n</code></pre> <p>If you run <code>python t.py</code> and your output looks like this: <pre><code>pandas result: ['a', 'b']\nPolars result: ['a', 'b']\n</code></pre></p> <p>then all your installations worked perfectly.</p> <p>Let's learn about what you just did, and what <code>dataframe-api-compat</code> can do for you.</p>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#api-reference","title":"API Reference","text":"<p>Please refer to the Dataframe API Spec.</p> <p>Note that the spec is not specific to pandas and Polars - if you follow it, then your code will also be compatible with any other packages which implements the spec.</p>"},{"location":"reference/#dataframe-interchange-protocol","title":"Dataframe Interchange Protocol","text":"<p>Standardised way of interchanging data between libraries, see here.</p>"},{"location":"reference/#array-api","title":"Array API","text":"<p>Array counterpart to the DataFrame API, see here.</p>"},{"location":"basics/column/","title":"Column","text":"<p>In dataframe.md, you learned how to write a dataframe-agnostic function.</p> <p>We only used DataFrame methods there - but what if we need to operate on its columns?</p>"},{"location":"basics/column/#extracting-a-column","title":"Extracting a column","text":""},{"location":"basics/column/#example-1-filter-based-on-a-columns-values","title":"Example 1: filter based on a column's values","text":"<pre><code>def my_func(df):\n    df_s = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    df_s = df_s.filter(df_s.col('a') &gt; 0)\n    return df_s.dataframe\n</code></pre> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>   a  b\n0  1  5\n1  3 -3\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df).collect())\n</code></pre> <pre><code>shape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 5   \u2502\n\u2502 3   \u2506 -3  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </p>"},{"location":"basics/column/#example-2-multiply-a-columns-values-by-a-constant","title":"Example 2: multiply a column's values by a constant","text":"<p>Let's write a dataframe-agnostic function which multiplies the values in column <code>'a'</code> by 2.</p> <pre><code>def my_func(df):\n    df_s = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    df_s = df_s.assign(df_s.col('a')*2)\n    return df_s.dataframe\n</code></pre> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>   a  b\n0 -2  3\n1  2  5\n2  6 -3\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df).collect())\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -2  \u2506 3   \u2502\n\u2502 2   \u2506 5   \u2502\n\u2502 6   \u2506 -3  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </p> <p>Note that column <code>'a'</code> was overwritten. If we had wanted to add a new column called <code>'c'</code> containing column <code>'a'</code>'s values multiplied by 2, we could have used <code>Column.rename</code>:</p> <pre><code>def my_func(df):\n    df_s = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    df_s = df_s.assign((df_s.col('a')*2).rename('c'))\n    return df_s.dataframe\n</code></pre> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>   a  b  c\n0 -1  3 -2\n1  1  5  2\n2  3 -3  6\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df).collect())\n</code></pre> <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -1  \u2506 3   \u2506 -2  \u2502\n\u2502 1   \u2506 5   \u2506 2   \u2502\n\u2502 3   \u2506 -3  \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </p>"},{"location":"basics/column/#example-3-cross-dataframe-column-comparisons","title":"Example 3: cross-dataframe column comparisons","text":"<p>You might expect a function like the following to just work:</p> <pre><code>def my_func(df1, df2):\n    df1_s = df1.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    df2_s = df2.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    df1_s.filter(df2_s.col('a') &gt; 0)\n    return df_s.dataframe\n</code></pre> <p>However, if you tried passing two different dataframes to this function, you'd get a message saying something like: <pre><code>cannot compare columns from different dataframes\n</code></pre></p> <p>This is because <code>Column</code>s for the Polars implementation are backed by <code>polars.Expr</code>s. The error is there to ensure that the Polars and pandas implementations behave in the same way. If you wish to compare columns from different dataframes, you should first join the dataframes. For example: <pre><code>def my_func(df1, df2):\n    df1_s = df1.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    df2_s = df2.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    df1_s = df1_s.join(\n        df2_s.rename({'a': 'a_right'}),\n        left_on='b',\n        right_on='b',\n        how='inner',\n    )\n    df1_s.filter(df1_s.col('a_right') &gt; 0)\n    return df1_s.dataframe\n</code></pre></p> pandasPolars <p><pre><code>import pandas as pd\n\ndf1 = pd.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\ndf2 = pd.DataFrame({'a': [5, 4], 'b': [5, -3]})\nprint(my_func(df1, df2))\n</code></pre> <pre><code>   a  b  a_right\n0  1  5        5\n1  3 -3        4\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf1 = pl.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\ndf2 = pl.DataFrame({'a': [5, 4], 'b': [5, -3]})\nprint(my_func(df1, df2).collect())\n</code></pre> <pre><code>shape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 a_right \u2502\n\u2502 --- \u2506 --- \u2506 ---     \u2502\n\u2502 i64 \u2506 i64 \u2506 i64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 5   \u2506 5       \u2502\n\u2502 3   \u2506 -3  \u2506 4       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </p>"},{"location":"basics/complete_example/","title":"Complete example","text":"<p>We're going to write a dataframe-agnostic \"Standard Scaler\". This class will have <code>fit</code> and <code>transform</code> methods (like <code>scikit-learn</code> transformers), and will work agnosstically for pandas and Polars.</p> <p>We'll need to write two methods: - <code>fit</code>: find the mean and standard deviation for each column from a given training set; - <code>transform</code>: scale a given dataset with the mean and standard deviations calculated   during <code>fit</code>.</p> <p>The <code>fit</code> method is a bit complicated, so let's start with <code>transform</code>. Suppose we've already calculated the mean and standard deviation of each column, and have stored them in attributes <code>self.means</code> and <code>self.std_devs</code>.</p>"},{"location":"basics/complete_example/#transform-method","title":"Transform method","text":"<p>The general strategy will be: 1. opt-in to the Dataframe API Standard by calling <code>__dataframe_consortium_standard__</code>; 2. calculate new columns using methods from the Dataframe API Standard:    - <code>DataFrame.col</code>    - <code>DataFrame.assign</code> 3. return the original (non-standard-compliant) dataframe to the user by calling    <code>DataFrame.dataframe</code></p> <pre><code>class StandardScalar:\n    def transform(self, df):\n        df = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n        new_columns = [(col - self.means[col.name])/self.std_devs[col_name] for col in df.iter_columns()]\n        df = df.assign(*new_columns)\n        return df.dataframe\n</code></pre> <p>Note that all the calculations here can stay lazy if the underlying library permits it. For Polars, the return value is a <code>polars.LazyFrame</code> - it is the caller's responsibility to call <code>.collect()</code> on the result if they want to materialise its values.</p>"},{"location":"basics/complete_example/#fit-method","title":"Fit method","text":"<p>Unlike the <code>transform</code> method, <code>fit</code> cannot stay lazy, as we need to compute concrete values for the means and standard deviations.</p> <p>We will need to use the <code>persist</code> method here, see persist. We need to call it in order to be able to extract concrete values in <code>Column.get_value</code>.</p> <pre><code>class StandardScalar:\n    def fit(self, df):\n        df = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n        ns = df.__dataframe_namespace__()\n\n        means = [col.mean() for col in df.iter_columns()]\n        std_devs = [col.std() for col in df.iter_columns()]\n        df_means = df.assign(*means)\n        df_std_devs = df.assign(*std_devs)\n        df = ns.concat([means, std_devs])\n        df = df.persist()\n        means = {col.name: float(col.get_value(0)) for col in df.iter_columns()}\n        std_devs = {col.name: float(col.get_value(1)) for col in df.iter_columns()}\n        std_devs = {}\n        self._means = means\n        self._std_devs = std_devs\n</code></pre>"},{"location":"basics/complete_example/#putting-it-all-together","title":"Putting it all together","text":"<p>Here is our dataframe-agnostic standard scaler: <pre><code>class StandardScaler:\n    def fit(self, df):\n        df = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n        ns = df.__dataframe_namespace__()\n\n        df = ns.concat([df.mean(), df.std()])\n        df = df.persist()\n        means = {col.name: float(col.get_value(0)) for col in df.iter_columns()}\n        std_devs = {col.name: float(col.get_value(1)) for col in df.iter_columns()}\n        self._means = means\n        self._std_devs = std_devs\n\n    def transform(self, df):\n        df = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n        new_columns = [(col - self._means[col.name])/self._std_devs[col.name] for col in df.iter_columns()]\n        df = df.assign(*new_columns)\n        return df.dataframe\n</code></pre></p> <p>Next, let's try running it. Note that <code>StandardScaler.transform</code> is completely lazy (it contains no <code>persist</code>) calls, so the output for Polars is a <code>polars.LazyFrame</code>. So, to see the output, we need to call <code>.collect</code>:</p> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 7]})\nscaler = StandardScaler()\nscaler.fit(df)\nprint(scaler.transform(df))\n</code></pre> <pre><code>     a         b\n0 -1.0 -0.872872\n1  0.0 -0.218218\n2  1.0  1.091089\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 7]})\nscaler = StandardScaler()\nscaler.fit(df)\nprint(scaler.transform(df).collect())\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b         \u2502\n\u2502 ---  \u2506 ---       \u2502\n\u2502 f64  \u2506 f64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -1.0 \u2506 -0.872872 \u2502\n\u2502 0.0  \u2506 -0.218218 \u2502\n\u2502 1.0  \u2506 1.091089  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </p>"},{"location":"basics/dataframe/","title":"DataFrame","text":"<p>To write a dataframe-agnostic function, the steps you'll want to follow are:</p> <ol> <li>Opt-in to the Dataframe API by calling <code>__dataframe_consortium_standard__</code> on your dataframe.</li> <li>Express your logic using methods from the Dataframe API    You may want to look at the official examples    for inspiration.</li> <li>If you need to return a dataframe to the user in its original library, call <code>DataFrame.dataframe</code>.</li> </ol> <p>Let's try writing a simple example.</p>"},{"location":"basics/dataframe/#example-1-group-by-and-mean","title":"Example 1: group-by and mean","text":"<p>Make a Python file <code>t.py</code> with the following content: <pre><code>def func(df):\n    # 1. Opt-in to the API Standard\n    df_s = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    # 2. Use methods from the API Standard spec\n    df_s = df_s.group_by('a').mean()\n    # 3. Return a library from the user's original library\n    return df_s.dataframe\n</code></pre> Let's try it out:</p> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'a': [1, 1, 2], 'b': [4, 5, 6]})\nprint(func(df))\n</code></pre> <pre><code>   a    b\n0  1  4.5\n1  2  6.0\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'a': [1, 1, 2], 'b': [4, 5, 6]})\nprint(func(df))\n</code></pre> <pre><code>naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n\nAGGREGATE\n    [col(\"b\").mean()] BY [col(\"a\")] FROM\n  DF [\"a\", \"b\"]; PROJECT */2 COLUMNS; SELECTION: \"None\"\n</code></pre> </p> <p>If you look at the two outputs, you'll see that:</p> <ul> <li>For pandas, the output is a <code>pandas.DataFrame</code>.</li> <li>But for Polars, the output is a <code>polars.LazyFrame</code>.</li> </ul> <p>This is because the Dataframe API only has a single <code>DataFrame</code> class - so for Polars, all operations are done lazily in order to make full use of Polars' query engine. If you want to convert that to a <code>polars.DataFrame</code>, it is the caller's responsibility to call <code>.collect</code>. Check the modified example below:</p> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'a': [1, 1, 2], 'b': [4, 5, 6]})\nprint(func(df))\n</code></pre> <pre><code>   a    b\n0  1  4.5\n1  2  6.0\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'a': [1, 1, 2], 'b': [4, 5, 6]})\nprint(func(df).collect())\n</code></pre> <pre><code>shape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4.5 \u2502\n\u2502 2   \u2506 6.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </p>"},{"location":"basics/persist/","title":"Persist","text":"<p>If you're used to pandas, then you might have been surprised to see <code>DataFrame.persist</code> is an example from column.md. But...what is it?</p> <p>The basic idea is:</p> <p>If you call <code>.persist</code>, then computation prior to this point won't be repeated.</p> <p>If this is confusing, don't worry, we'll see an example. If you follow the rule:</p> <p>Call <code>.persist</code> as little and as late as possible, ideally just once per function / dataframe</p> <p>then you'll likely be fine.</p>"},{"location":"basics/persist/#why-do-we-need-it","title":"Why do we need it?","text":"<p>The <code>dataframe-api-compat</code> package is written with lazy computation in mind. For the Polars implementation, all objects are backed by lazy constructs:</p> <ul> <li><code>DataFrame</code>:</li> <li>by default, backed by <code>polars.LazyFrame</code></li> <li>if you call <code>persist</code>, backed by <code>polars.DataFrame</code></li> <li><code>Column</code>:</li> <li>by default, backed by <code>polars.Expr</code></li> <li>if you call <code>persist</code>, or if you called <code>persist</code> on     the dataframe it was derived from, backed by <code>polars.Series</code></li> <li><code>Scalar</code>:</li> <li>by default, backed by <code>polars.Expr</code></li> <li>if you call <code>persist</code>, or if you called <code>persist</code> on     the dataframe or column it was derived from, backed by     a Python scalar.</li> </ul> <p>All operations can be done lazily, except for: - <code>DataFrame.to_array()</code>, - <code>Column.to_array()</code>, - <code>DataFrame.shape</code>, - bringing a <code>Scalar</code> into Python, e.g. <code>float(df.col('a').mean())</code></p> <p>Let's see what you need to do when using <code>dataframe-api-compat</code> to achieve the above.</p>"},{"location":"basics/persist/#example-1-splitting-a-dataframe-and-converting-to-array","title":"Example 1: splitting a dataframe and converting to array","text":"<p>Say you have a DataFrame <code>df</code>, and want to split it into <code>features</code> and <code>target</code>, and want to convert both to numpy arrays. Let's see how you can achieve this.</p> <p>If you try running the code below</p> <pre><code>def my_func(df):\n    df_s = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    x_train = df_s.drop('y').to_array()\n    y_train = df_s.col('y').to_array()\n    return x_train, y_train\n</code></pre> <p>you'll get an error like: <pre><code>Method requires you to call `.persist` first.\n</code></pre></p> <p>Here's how to fix up the function so it runs: we add a single <code>persist</code>, just once, before splitting the dataframe within numpy:</p> <pre><code>import numpy as np\n\ndef my_func(df):\n    df_s = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    arr = df_s.persist().to_array()\n    target_idx = df_s.column_names.index('y')\n    x_train = np.delete(arr, target_idx, axis=1)\n    y_train = arr[:, target_idx]\n    return x_train, y_train\n</code></pre> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'x': [-1, 1, 3], 'y': [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>(array([[-1],\n       [ 1],\n       [ 3]]), array([ 3,  5, -3]))\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'x': [-1, 1, 3], 'y': [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>(array([[-1],\n       [ 1],\n       [ 3]]), array([ 3,  5, -3]))\n</code></pre> </p> <p>If you find yourself repeatedly calling <code>persist</code>, you might be re-triggering the same computation multiple times.</p>"},{"location":"basics/scalar/","title":"Scalar","text":"<p>In column.md, you learned how to write a dataframe-agnostic function involving both dataframes and columns.</p> <p>But what if we want to extract scalars as well?</p>"},{"location":"basics/scalar/#example-1-center-features","title":"Example 1: center features","text":"<p>Let's try writing a function which, for each column, subtracts its mean.</p> <pre><code>def my_func(df):\n    df_s = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    new_columns = [col - col.mean() for col in df_s.iter_columns()]\n    df_s = df_s.assign(*new_columns)\n    return df_s.dataframe\n</code></pre> <p>Let's run it:</p> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>     a         b\n0 -2.0  1.333333\n1  0.0  3.333333\n2  2.0 -4.666667\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df).collect())\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b         \u2502\n\u2502 ---  \u2506 ---       \u2502\n\u2502 f64  \u2506 f64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -2.0 \u2506 1.333333  \u2502\n\u2502 0.0  \u2506 3.333333  \u2502\n\u2502 2.0  \u2506 -4.666667 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> </p> <p>The output looks as expected. <code>df.col(column_name).mean()</code> returns a <code>Scalar</code>, which can be combined with a <code>Column</code> from the same dataframe. Just like we saw for <code>Column</code>s, scalars from different dataframes cannot be compared - you'll first need to join the underlying dataframes.</p>"},{"location":"basics/scalar/#example-2-store-mean-of-each-column-as-python-float","title":"Example 2: Store mean of each column as Python float","text":"<p>We saw in the above example that <code>df.col(column_name).mean()</code> returns a <code>Scalar</code>, which may be lazy. In particular, it's not a Python scalar. So, how would we force execution and store a Python scalar, in a dataframe-agnostic manner?</p> <pre><code>def my_func(df):\n    df_s = df.__dataframe_consortium_standard__(api_version='2023.11-beta')\n    # We'll learn more about `persist` in the next page\n    df_s = df_s.mean().persist()\n    means = []\n    for column_name in df_s.column_names:\n        mean = float(df_s.col(column_name).get_value(0))\n        means.append(mean)\n    return means\n</code></pre> <p>Let's run it:</p> pandasPolars <p><pre><code>import pandas as pd\n\ndf = pd.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>[1.0, 1.6666666666666667]\n</code></pre> </p> <p><pre><code>import polars as pl\n\ndf = pl.DataFrame({'a': [-1, 1, 3], 'b': [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>[1.0, 1.6666666666666667]\n</code></pre> </p> <p>We'll learn more about <code>DataFrame.persist</code> in the next slide.</p>"}]}